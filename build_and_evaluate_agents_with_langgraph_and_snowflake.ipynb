{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building a Multi-Agent Supervisor Workflow with LangGraph and Snowflake\n",
        "\n",
        "This notebook demonstrates how to build a **multi-agent supervisor architecture** using LangGraph and Snowflake Cortex Agents. The workflow consists of:\n",
        "\n",
        "- **Supervisor**: An AI coordinator that routes queries to specialized agents and synthesizes their responses\n",
        "- **Content Agent**: Handles customer feedback, sentiment analysis, and communication intelligence\n",
        "- **Data Analyst Agent**: Handles customer behavior, business metrics, and predictive analytics\n",
        "- **Research Agent**: Handles market intelligence, strategic analysis, and competitive insights\n",
        "\n",
        "## Architecture Overview\n",
        "\n",
        "```\n",
        "START â†’ Supervisor (Route) â†’ Specialized Agent â†’ Supervisor (Synthesize) â†’ END\n",
        "```\n",
        "\n",
        "The supervisor makes two passes:\n",
        "1. **Routing Pass**: Analyzes the query and routes to the appropriate agent\n",
        "2. **Synthesis Pass**: Combines agent output into an executive summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install and Import Dependencies\n",
        "\n",
        "First, let's import all the necessary libraries. We'll need:\n",
        "- **LangChain Core**: For message types and prompt templates\n",
        "- **LangChain Snowflake**: For Snowflake-specific integrations (ChatSnowflake, SnowflakeCortexAgent)\n",
        "- **LangGraph**: For building the stateful workflow graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All imports loaded successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/langgraph_snowflake/lib/python3.11/site-packages/langchain_snowflake/chat_models/base.py:26: UserWarning: Field name \"schema\" in \"ChatSnowflake\" shadows an attribute in parent \"BaseChatModel\"\n",
            "  class ChatSnowflake(\n"
          ]
        }
      ],
      "source": [
        "# LangGraph imports\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.types import Command\n",
        "from langgraph.graph.message import MessagesState\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Snowflake imports\n",
        "from langchain_snowflake import ChatSnowflake, SnowflakeCortexAgent, create_session_from_env\n",
        "from snowflake.snowpark import Session\n",
        "\n",
        "# Utility imports\n",
        "import json\n",
        "import os\n",
        "from typing import Dict, List, Optional, Literal\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "print(\"âœ… All imports loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Define the Workflow State\n",
        "\n",
        "LangGraph uses a **state** object that flows through the graph. We'll use the built-in `MessagesState` which provides:\n",
        "- A `messages` list that accumulates all messages in the conversation\n",
        "- Automatic message deduplication and ordering\n",
        "\n",
        "The state is shared across all nodes and gets updated as the workflow progresses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… State defined\n"
          ]
        }
      ],
      "source": [
        "# Extend MessagesState to include execution plan tracking\n",
        "class State(MessagesState):\n",
        "    \"\"\"Extended state that tracks execution plan and progress.\"\"\"\n",
        "    plan: Optional[Dict] = None  # The supervisor's explicit plan\n",
        "    current_step: int = 0  # Current step being executed in the plan\n",
        "\n",
        "print(\"âœ… State defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Snowflake Session\n",
        "\n",
        "We need to establish a connection to Snowflake. The `create_session_from_env()` function reads credentials from environment variables:\n",
        "- `SNOWFLAKE_ACCOUNT`\n",
        "- `SNOWFLAKE_USER`\n",
        "- `SNOWFLAKE_PASSWORD`\n",
        "- `SNOWFLAKE_DATABASE`\n",
        "- `SNOWFLAKE_SCHEMA`\n",
        "- `SNOWFLAKE_WAREHOUSE`\n",
        "\n",
        "Make sure you have a `.env` file with these variables set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Snowflake session created successfully!\n",
            "   Database: CUSTOMER_INTELLIGENCE_DB\n",
            "   Schema: PUBLIC\n",
            "   Warehouse: COMPUTE_WH\n"
          ]
        }
      ],
      "source": [
        "# Create Snowflake session from environment variables\n",
        "try:\n",
        "    session = create_session_from_env()\n",
        "    \n",
        "    # Get database and schema, stripping any quotes that Snowflake might add\n",
        "    current_database = session.get_current_database().strip('\"')\n",
        "    current_schema = session.get_current_schema().strip('\"')\n",
        "    \n",
        "    # IMPORTANT: Ensure warehouse is set - required for Cortex Analyst tools\n",
        "    warehouse = os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH')\n",
        "    session.sql(f\"USE WAREHOUSE {warehouse}\").collect()\n",
        "    current_warehouse = session.get_current_warehouse()\n",
        "    if current_warehouse:\n",
        "        current_warehouse = current_warehouse.strip('\"')\n",
        "    \n",
        "    print(\"âœ… Snowflake session created successfully!\")\n",
        "    print(f\"   Database: {current_database}\")\n",
        "    print(f\"   Schema: {current_schema}\")\n",
        "    print(f\"   Warehouse: {current_warehouse}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Snowflake connection failed: {e}\")\n",
        "    print(\"   Please check your .env file and Snowflake credentials\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Initialize the Supervisor Model\n",
        "\n",
        "The **Supervisor** is the brain of our multi-agent system. It uses Snowflake's Cortex LLM service (`ChatSnowflake`) to:\n",
        "1. Analyze incoming queries\n",
        "2. Route them to the appropriate specialized agent\n",
        "3. Synthesize the agent's response into an executive summary\n",
        "\n",
        "We use `claude-4-sonnet` with low temperature (0.1) for consistent, deterministic routing decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Supervisor model initialized!\n",
            "   Model: claude-4-sonnet\n",
            "   Temperature: 0.1 (deterministic)\n",
            "   Max tokens: 2000\n"
          ]
        }
      ],
      "source": [
        "# Initialize the supervisor model using Snowflake Cortex\n",
        "supervisor_model = ChatSnowflake(\n",
        "    session=session,\n",
        "    model=\"claude-4-sonnet\",  # Claude 4 Sonnet via Snowflake Cortex\n",
        "    temperature=0.1,          # Low temperature for consistent routing\n",
        "    max_tokens=2000           # Limit response length\n",
        ")\n",
        "\n",
        "print(\"âœ… Supervisor model initialized!\")\n",
        "print(f\"   Model: claude-4-sonnet\")\n",
        "print(f\"   Temperature: 0.1 (deterministic)\")\n",
        "print(f\"   Max tokens: 2000\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Initialize Specialized Cortex Agents\n",
        "\n",
        "Now we initialize our three specialized **Snowflake Cortex Agents**. These agents are pre-configured in Snowflake with access to specific tools, data sources, and instructions.\n",
        "\n",
        "Each agent is specialized for a different domain:\n",
        "| Agent | Specialization |\n",
        "|-------|----------------|\n",
        "| **CONTENT_AGENT** | Customer feedback, sentiment analysis, support tickets |\n",
        "| **DATA_ANALYST_AGENT** | Metrics, behavior patterns, churn prediction, analytics |\n",
        "| **RESEARCH_AGENT** | Market research, competitive analysis, strategic insights |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… CONTENT_AGENT initialized\n",
            "âœ… DATA_ANALYST_AGENT initialized\n",
            "âœ… RESEARCH_AGENT initialized\n",
            "\n",
            "ğŸ“ All agents loaded from: SNOWFLAKE_INTELLIGENCE.AGENTS\n",
            "ğŸ“ Using warehouse: COMPUTE_WH\n"
          ]
        }
      ],
      "source": [
        "# Agent configuration - agents are stored in the SNOWFLAKE_INTELLIGENCE.AGENTS schema\n",
        "AGENT_DATABASE = \"SNOWFLAKE_INTELLIGENCE\"\n",
        "AGENT_SCHEMA = \"AGENTS\"\n",
        "AGENT_WAREHOUSE = os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH')\n",
        "\n",
        "# Initialize Content Agent - Customer feedback and sentiment specialist\n",
        "content_agent = SnowflakeCortexAgent(\n",
        "    session=session,\n",
        "    name=\"CONTENT_AGENT\",\n",
        "    database=AGENT_DATABASE,\n",
        "    schema=AGENT_SCHEMA,\n",
        "    warehouse=AGENT_WAREHOUSE,  # Required for tool execution\n",
        "    description=\"Customer feedback, sentiment analysis, and communication intelligence specialist\",\n",
        ")\n",
        "print(\"âœ… CONTENT_AGENT initialized\")\n",
        "\n",
        "# Initialize Data Analyst Agent - Metrics and analytics specialist\n",
        "data_analyst_agent = SnowflakeCortexAgent(\n",
        "    session=session,\n",
        "    name=\"DATA_ANALYST_AGENT\",\n",
        "    database=AGENT_DATABASE,\n",
        "    schema=AGENT_SCHEMA,\n",
        "    warehouse=AGENT_WAREHOUSE,  # Required for Cortex Analyst text-to-SQL\n",
        "    description=\"Customer behavior, business metrics, and predictive analytics specialist\",\n",
        ")\n",
        "print(\"âœ… DATA_ANALYST_AGENT initialized\")\n",
        "\n",
        "# Initialize Research Agent - Market intelligence specialist\n",
        "research_agent = SnowflakeCortexAgent(\n",
        "    session=session,\n",
        "    name=\"RESEARCH_AGENT\",\n",
        "    database=AGENT_DATABASE,\n",
        "    schema=AGENT_SCHEMA,\n",
        "    warehouse=AGENT_WAREHOUSE,  # Required for Cortex Analyst text-to-SQL\n",
        "    description=\"Market intelligence, strategic analysis, and competitive insights specialist\",\n",
        ")\n",
        "print(\"âœ… RESEARCH_AGENT initialized\")\n",
        "\n",
        "print(f\"\\nğŸ“ All agents loaded from: {AGENT_DATABASE}.{AGENT_SCHEMA}\")\n",
        "print(f\"ğŸ“ Using warehouse: {AGENT_WAREHOUSE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Create Supervisor Prompts\n",
        "\n",
        "The supervisor uses two prompts depending on its current task:\n",
        "\n",
        "### 1. Planning Prompt\n",
        "Creates an **explicit, detailed execution plan** before any agents are called. This ensures transparency, accountability, and methodical execution. The plan includes:\n",
        "\n",
        "| Element | Description |\n",
        "|---------|-------------|\n",
        "| **Plan Summary** | Concise description of the analytical approach |\n",
        "| **Steps** | Ordered list of agent calls with detailed specifications |\n",
        "| **Step Dependencies** | How data flows between steps |\n",
        "| **Combination Strategy** | Methodology for synthesizing all results |\n",
        "| **Expected Final Output** | What the final deliverable must contain |\n",
        "\n",
        "Each step in the plan specifies:\n",
        "- **Agent**: Which specialized agent to call\n",
        "- **Purpose**: Why this agent is needed\n",
        "- **Tools to Use**: Specific tools (Cortex Search, Churn Model, etc.)\n",
        "- **Data Sources**: Tables and data to query\n",
        "- **Methodology**: Step-by-step approach for the agent\n",
        "- **Specific Queries**: Questions the agent must answer\n",
        "- **Metrics to Collect**: KPIs and data points to gather\n",
        "- **Expected Output**: What the agent should deliver\n",
        "- **Success Criteria**: How to verify the step succeeded\n",
        "- **Dependencies**: Which previous steps this depends on\n",
        "\n",
        "### 2. Synthesis Prompt\n",
        "Used after all agents complete to combine findings into a comprehensive executive summary. The synthesis:\n",
        "- Follows the combination strategy from the plan\n",
        "- Verifies success criteria for each step\n",
        "- Correlates findings across agents using step dependencies\n",
        "- Meets the expected final output requirements\n",
        "- Includes quantitative analysis, risk assessment, and prioritized recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Planning prompt updated - detailed tool/data source/methodology specifications\n"
          ]
        }
      ],
      "source": [
        "# Planning Prompt - Creates detailed, actionable execution plans\n",
        "planning_prompt = \"\"\"\n",
        "You are an Executive AI Assistant supervisor. Create DETAILED, ACTIONABLE execution plans.\n",
        "\n",
        "**CRITICAL: Plans must specify tools, data sources, and methodology - not just goals.**\n",
        "\n",
        "**AVAILABLE AGENTS AND THEIR TOOLS:**\n",
        "\n",
        "| Agent | Tools Available | Data Sources | Capabilities |\n",
        "|-------|-----------------|--------------|--------------|\n",
        "| CONTENT_AGENT | cortex_search | SUPPORT_TICKETS table via Cortex Search index | Semantic search on ticket text; returns ticket_id, customer_id, ticket_text, created_date, category |\n",
        "| DATA_ANALYST_AGENT | cortex_analyst (text-to-SQL) | CUSTOMERS table, CUSTOMER_METRICS table | SQL queries for satisfaction_score, contract_status, contract_end_date, churn_probability, usage_metrics, tier |\n",
        "| RESEARCH_AGENT | cortex_analyst (text-to-SQL) | CUSTOMER_ANALYTICS table, MARKET_DATA table | SQL queries for customer_lifetime_value, industry, market_segment, acquisition_channel, revenue |\n",
        "\n",
        "**PLANNING RULES:**\n",
        "1. **Specify the tool** each agent will use (cortex_search or cortex_analyst)\n",
        "2. **Identify data sources** - which tables/indexes will be queried\n",
        "3. **Define methodology** - what query/search approach will be used\n",
        "4. **Set scope** - filters, time ranges, segments to include\n",
        "5. **Use multiple agents** when query requires data from different sources\n",
        "\n",
        "**MULTI-AGENT PATTERNS:**\n",
        "\n",
        "| Query Pattern | Agents & Tools | Data Flow |\n",
        "|--------------|----------------|-----------|\n",
        "| \"[risk/metrics] for [complaint type]\" | CONTENT_AGENT(cortex_search) â†’ DATA_ANALYST_AGENT(cortex_analyst) | Search tickets â†’ Get customer_ids â†’ Query metrics for those customers |\n",
        "| \"CLV/revenue by [segment]\" | RESEARCH_AGENT(cortex_analyst) | Single SQL aggregation on CUSTOMER_ANALYTICS |\n",
        "\n",
        "**JSON Response Format:**\n",
        "{{\n",
        "    \"plan_summary\": \"[AGENT(s)] will use [TOOL(s)] to query [DATA_SOURCE(s)] for [GOAL]\",\n",
        "    \"steps\": [\n",
        "        {{\n",
        "            \"step_number\": 1,\n",
        "            \"agent\": \"AGENT_NAME\",\n",
        "            \"tool\": \"cortex_search OR cortex_analyst\",\n",
        "            \"data_source\": \"Table or index name\",\n",
        "            \"purpose\": \"Specific analytical task\",\n",
        "            \"methodology\": \"How the tool will be used (search terms, query approach, filters)\",\n",
        "            \"scope\": \"Time range, segments, filters to apply\",\n",
        "            \"expected_output\": \"Specific columns/fields: field1, field2, field3\",\n",
        "            \"uses_data_from\": []\n",
        "        }}\n",
        "    ],\n",
        "    \"combination_strategy\": \"How results will be correlated/synthesized\",\n",
        "    \"expected_final_output\": \"Detailed specification with exact deliverables\"\n",
        "}}\n",
        "\n",
        "**Example - Multi-Agent (churn risk + complaints):**\n",
        "\n",
        "Query: \"Assess churn risk for customers complaining about API issues\"\n",
        "{{\n",
        "    \"plan_summary\": \"CONTENT_AGENT will use cortex_search on SUPPORT_TICKETS to find API complaints, then DATA_ANALYST_AGENT will use cortex_analyst to query CUSTOMER_METRICS for churn indicators\",\n",
        "    \"steps\": [\n",
        "        {{\n",
        "            \"step_number\": 1,\n",
        "            \"agent\": \"CONTENT_AGENT\",\n",
        "            \"tool\": \"cortex_search\",\n",
        "            \"data_source\": \"SUPPORT_TICKETS (Cortex Search index)\",\n",
        "            \"purpose\": \"Find support tickets mentioning API issues and extract customer identifiers\",\n",
        "            \"methodology\": \"Semantic search for 'API error', 'API issue', 'API problem', 'integration failure'\",\n",
        "            \"scope\": \"All tickets, no time filter (or last 12 months if volume is high)\",\n",
        "            \"expected_output\": \"ticket_id, customer_id, ticket_text, created_date for each matching ticket\",\n",
        "            \"uses_data_from\": []\n",
        "        }},\n",
        "        {{\n",
        "            \"step_number\": 2,\n",
        "            \"agent\": \"DATA_ANALYST_AGENT\",\n",
        "            \"tool\": \"cortex_analyst\",\n",
        "            \"data_source\": \"CUSTOMER_METRICS table joined with CUSTOMERS table\",\n",
        "            \"purpose\": \"Retrieve churn risk indicators for customers identified in step 1\",\n",
        "            \"methodology\": \"SQL query filtering by customer_ids from step 1, selecting risk metrics\",\n",
        "            \"scope\": \"Customers identified in step 1 only\",\n",
        "            \"expected_output\": \"customer_id, satisfaction_score, contract_status, contract_end_date, churn_probability\",\n",
        "            \"uses_data_from\": [1]\n",
        "        }}\n",
        "    ],\n",
        "    \"combination_strategy\": \"Join ticket complaints with customer metrics by customer_id; rank by churn_probability descending\",\n",
        "    \"expected_final_output\": \"Table with columns: customer_id, complaint_summary, satisfaction_score, contract_status, churn_probability, risk_level (HIGH/MEDIUM/LOW based on churn_probability > 0.7/0.4/else)\"\n",
        "}}\n",
        "\n",
        "**Example - Single Agent (CLV by industry):**\n",
        "\n",
        "Query: \"What industries have the highest customer lifetime value?\"\n",
        "{{\n",
        "    \"plan_summary\": \"RESEARCH_AGENT will use cortex_analyst to query CUSTOMER_ANALYTICS for CLV aggregated by industry\",\n",
        "    \"steps\": [\n",
        "        {{\n",
        "            \"step_number\": 1,\n",
        "            \"agent\": \"RESEARCH_AGENT\",\n",
        "            \"tool\": \"cortex_analyst\",\n",
        "            \"data_source\": \"CUSTOMER_ANALYTICS table\",\n",
        "            \"purpose\": \"Calculate average and total CLV by industry with customer counts\",\n",
        "            \"methodology\": \"SQL aggregation: GROUP BY industry, calculate AVG(customer_lifetime_value), SUM(customer_lifetime_value), COUNT(*)\",\n",
        "            \"scope\": \"All active customers, exclude churned (if status column exists)\",\n",
        "            \"expected_output\": \"industry, avg_clv, total_clv, customer_count, ordered by avg_clv DESC\",\n",
        "            \"uses_data_from\": []\n",
        "        }}\n",
        "    ],\n",
        "    \"combination_strategy\": \"Present ranked results with interpretation of top industries\",\n",
        "    \"expected_final_output\": \"Ranked table: industry, average_clv, total_clv, customer_count with top 3 industries highlighted as expansion opportunities\"\n",
        "}}\n",
        "\n",
        "**Example - Single Agent (complaint themes):**\n",
        "\n",
        "Query: \"What are customers complaining about?\"\n",
        "{{\n",
        "    \"plan_summary\": \"CONTENT_AGENT will use cortex_search on SUPPORT_TICKETS to identify and categorize complaint themes\",\n",
        "    \"steps\": [\n",
        "        {{\n",
        "            \"step_number\": 1,\n",
        "            \"agent\": \"CONTENT_AGENT\",\n",
        "            \"tool\": \"cortex_search\",\n",
        "            \"data_source\": \"SUPPORT_TICKETS (Cortex Search index)\",\n",
        "            \"purpose\": \"Search for negative sentiment tickets and extract common themes\",\n",
        "            \"methodology\": \"Semantic search for complaint indicators; analyze returned tickets for theme clustering\",\n",
        "            \"scope\": \"Last 90 days, categories: complaint, issue, problem\",\n",
        "            \"expected_output\": \"ticket_id, customer_id, ticket_text, category, created_date; grouped by identified theme\",\n",
        "            \"uses_data_from\": []\n",
        "        }}\n",
        "    ],\n",
        "    \"combination_strategy\": \"Cluster complaints by theme, count frequency, select representative examples\",\n",
        "    \"expected_final_output\": \"Top 5 complaint themes with: theme_name, ticket_count, percentage_of_total, 2-3 example ticket summaries\"\n",
        "}}\n",
        "\n",
        "**Query:** {input}\n",
        "\n",
        "**RESPOND WITH ONLY THE JSON**\n",
        "\"\"\"\n",
        "\n",
        "planning_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", planning_prompt),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "print(\"âœ… Planning prompt updated - detailed tool/data source/methodology specifications\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Synthesis prompt updated - constructive and confident\n"
          ]
        }
      ],
      "source": [
        "# Synthesis Prompt - Combines agent results into a clear, confident answer\n",
        "synthesis_prompt = \"\"\"\n",
        "You are an Executive AI Assistant synthesizing agent results into a clear answer.\n",
        "\n",
        "**Original Question**: {question}\n",
        "\n",
        "**Plan Summary**: {plan_summary}\n",
        "\n",
        "**Agent Results**:\n",
        "{agent_outputs}\n",
        "\n",
        "**Your Task**: Provide a clear, confident answer to the question using the data returned.\n",
        "\n",
        "**Synthesis Guidelines:**\n",
        "1. **Lead with the answer** - Start with the key finding that answers the question\n",
        "2. **Present what you learned** - Use the actual data returned by agents\n",
        "3. **Be confident** - Don't apologize for what wasn't analyzed\n",
        "4. **Be concise** - Executive summary style, not exhaustive reports\n",
        "5. **Add value** - Include actionable insights based on the data\n",
        "\n",
        "**DO NOT:**\n",
        "- List \"missing data\" or \"incomplete analysis\"\n",
        "- Mark steps as \"met/not met\"\n",
        "- Apologize for limitations\n",
        "- Add disclaimers about data gaps\n",
        "- Suggest the analysis is incomplete if you have enough to answer the question\n",
        "\n",
        "**Response Format:**\n",
        "\n",
        "## Summary\n",
        "[Direct answer to the question in 2-3 sentences with key metrics]\n",
        "\n",
        "## Key Findings\n",
        "[3-5 bullet points of important insights from the data]\n",
        "\n",
        "## Recommendations\n",
        "[2-3 actionable next steps based on findings]\n",
        "\n",
        "Keep the response focused and actionable. If the data answers the question, present it confidently.\n",
        "\"\"\"\n",
        "\n",
        "synthesis_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", synthesis_prompt),\n",
        "    (\"human\", \"Synthesize the agent results into a clear answer to the original question.\")\n",
        "])\n",
        "\n",
        "print(\"âœ… Synthesis prompt updated - constructive and confident\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Create Helper Functions\n",
        "\n",
        "We need several helper functions to work with the message state:\n",
        "\n",
        "1. **`get_latest_human_message`**: Extracts the user's query from the message list\n",
        "2. **`has_agent_response`**: Checks if any specialized agent has already responded\n",
        "3. **`get_agent_output`**: Retrieves the agent's response for synthesis\n",
        "\n",
        "These helpers make our node functions cleaner and handle various message formats (including LangGraph Studio's format).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All helper functions defined:\n",
            "   - get_latest_human_message()\n",
            "   - has_plan()\n",
            "   - get_current_step()\n",
            "   - is_plan_complete()\n",
            "   - get_all_agent_outputs()\n"
          ]
        }
      ],
      "source": [
        "def get_latest_human_message(messages: List[BaseMessage]) -> str:\n",
        "    \"\"\"Extract the latest human message content from the message list.\"\"\"\n",
        "    if not messages:\n",
        "        return \"\"\n",
        "    for msg in reversed(messages):\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            content = msg.content\n",
        "            if isinstance(content, list):\n",
        "                for item in content:\n",
        "                    if isinstance(item, dict) and item.get(\"type\") == \"text\":\n",
        "                        return item.get(\"text\", \"\")\n",
        "                    elif isinstance(item, str):\n",
        "                        return item\n",
        "            return str(content)\n",
        "        if isinstance(msg, dict):\n",
        "            if msg.get(\"type\") == \"human\" or msg.get(\"role\") == \"user\":\n",
        "                content = msg.get(\"content\", \"\")\n",
        "                if isinstance(content, list):\n",
        "                    for item in content:\n",
        "                        if isinstance(item, dict) and item.get(\"type\") == \"text\":\n",
        "                            return item.get(\"text\", \"\")\n",
        "                return str(content)\n",
        "    return \"\"\n",
        "\n",
        "# Agent names for identification\n",
        "AGENT_NAMES = [\"CONTENT_AGENT\", \"DATA_ANALYST_AGENT\", \"RESEARCH_AGENT\"]\n",
        "\n",
        "def has_plan(state) -> bool:\n",
        "    \"\"\"Check if an execution plan has been created.\"\"\"\n",
        "    return state.get(\"plan\") is not None\n",
        "\n",
        "def get_current_step(state):\n",
        "    \"\"\"Get the current step from the execution plan.\"\"\"\n",
        "    plan = state.get(\"plan\")\n",
        "    current_step_idx = state.get(\"current_step\", 0)\n",
        "    if plan and \"steps\" in plan:\n",
        "        steps = plan[\"steps\"]\n",
        "        if current_step_idx < len(steps):\n",
        "            return steps[current_step_idx]\n",
        "    return None\n",
        "\n",
        "def is_plan_complete(state) -> bool:\n",
        "    \"\"\"Check if all steps in the plan have been executed.\"\"\"\n",
        "    plan = state.get(\"plan\")\n",
        "    current_step_idx = state.get(\"current_step\", 0)\n",
        "    if plan and \"steps\" in plan:\n",
        "        return current_step_idx >= len(plan[\"steps\"])\n",
        "    return True\n",
        "\n",
        "def get_all_agent_outputs(messages) -> Dict[str, str]:\n",
        "    \"\"\"Get all agent outputs from the message list.\"\"\"\n",
        "    outputs = {}\n",
        "    for msg in messages:\n",
        "        if hasattr(msg, 'name') and msg.name in AGENT_NAMES:\n",
        "            content = msg.content if hasattr(msg, 'content') else str(msg)\n",
        "            outputs[msg.name] = content\n",
        "    return outputs\n",
        "\n",
        "print(\"âœ… All helper functions defined:\")\n",
        "print(\"   - get_latest_human_message()\")\n",
        "print(\"   - has_plan()\")\n",
        "print(\"   - get_current_step()\")\n",
        "print(\"   - is_plan_complete()\")\n",
        "print(\"   - get_all_agent_outputs()\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… format_agent_outputs_for_synthesis() defined\n"
          ]
        }
      ],
      "source": [
        "def format_agent_outputs_for_synthesis(outputs: Dict[str, str], plan: Dict) -> str:\n",
        "    \"\"\"Format agent outputs for synthesis - simple and clean.\"\"\"\n",
        "    formatted = []\n",
        "    for step in plan.get(\"steps\", []):\n",
        "        agent_name = step.get(\"agent\")\n",
        "        if agent_name in outputs:\n",
        "            output = outputs[agent_name]\n",
        "            formatted.append(f\"\"\"\n",
        "**{agent_name}** (Step {step.get('step_number')})\n",
        "Purpose: {step.get('purpose', 'N/A')}\n",
        "\n",
        "Results:\n",
        "{output}\n",
        "\"\"\")\n",
        "    return \"\\n\".join(formatted)\n",
        "\n",
        "print(\"âœ… format_agent_outputs_for_synthesis() defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Create Node Functions\n",
        "\n",
        "Now we define the **node functions** - the actual work units of our graph. Each node:\n",
        "- Receives the current state\n",
        "- Performs some action (LLM call, agent invocation, etc.)\n",
        "- Returns state updates (new messages to add)\n",
        "\n",
        "### Node Types:\n",
        "1. **Supervisor Node**: Handles routing AND synthesis (dual-purpose)\n",
        "2. **Agent Nodes**: Invoke specialized Cortex agents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… supervisor_node() with LLM-based context extraction\n"
          ]
        }
      ],
      "source": [
        "# Prompt for extracting relevant context between agents\n",
        "context_extraction_prompt = \"\"\"\n",
        "You are extracting relevant information from one agent's output to pass to the next agent.\n",
        "\n",
        "**Previous Agent Output:**\n",
        "{previous_output}\n",
        "\n",
        "**Next Agent's Task:**\n",
        "Agent: {next_agent}\n",
        "Purpose: {next_purpose}\n",
        "\n",
        "**Instructions:**\n",
        "Extract ONLY the specific data the next agent needs. Be concise - include:\n",
        "- Specific IDs, names, or identifiers mentioned\n",
        "- Key numeric values or metrics\n",
        "- Relevant findings that directly inform the next task\n",
        "\n",
        "Do NOT include:\n",
        "- General summaries or explanations\n",
        "- Formatting or markdown\n",
        "- Information not relevant to the next agent's specific task\n",
        "\n",
        "**Respond with a brief, data-focused context (2-4 sentences max). If no relevant data to pass, respond with \"No context needed.\"**\n",
        "\"\"\"\n",
        "\n",
        "context_extraction_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", context_extraction_prompt),\n",
        "    (\"human\", \"Extract context for {next_agent}\")\n",
        "])\n",
        "\n",
        "def extract_context_for_next_agent(messages: List[BaseMessage], current_step: Dict, supervisor_model) -> str:\n",
        "    \"\"\"Use LLM to intelligently extract relevant context from previous agent output for the next agent.\"\"\"\n",
        "    \n",
        "    # Check if this step uses data from previous steps\n",
        "    uses_data = current_step.get(\"uses_data_from\", [])\n",
        "    if not uses_data:\n",
        "        return \"\"\n",
        "    \n",
        "    # Get most recent agent output\n",
        "    previous_output = \"\"\n",
        "    for msg in reversed(messages):\n",
        "        if hasattr(msg, 'name') and msg.name in AGENT_NAMES:\n",
        "            previous_output = msg.content if hasattr(msg, 'content') else \"\"\n",
        "            break\n",
        "    \n",
        "    if not previous_output or len(previous_output) < 50:\n",
        "        return \"\"\n",
        "    \n",
        "    # Use LLM to extract relevant context\n",
        "    try:\n",
        "        extraction_chain = context_extraction_template | supervisor_model\n",
        "        response = extraction_chain.invoke({\n",
        "            \"previous_output\": previous_output[:3000],  # Limit input size\n",
        "            \"next_agent\": current_step.get(\"agent\", \"\"),\n",
        "            \"next_purpose\": current_step.get(\"purpose\", \"\")\n",
        "        })\n",
        "        \n",
        "        context = response.content if hasattr(response, 'content') else str(response)\n",
        "        \n",
        "        # Skip if no relevant context\n",
        "        if \"no context needed\" in context.lower() or len(context) < 10:\n",
        "            return \"\"\n",
        "        \n",
        "        return context.strip()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   âš ï¸ Context extraction error: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def supervisor_node(state: State) -> Command[Literal[\"CONTENT_AGENT\", \"DATA_ANALYST_AGENT\", \"RESEARCH_AGENT\", \"__end__\"]]:\n",
        "    \"\"\"\n",
        "    Supervisor node that handles planning, execution routing, and synthesis.\n",
        "    Uses LLM to intelligently extract context between agents.\n",
        "    \"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "    plan = state.get(\"plan\")\n",
        "    current_step_idx = state.get(\"current_step\", 0)\n",
        "    \n",
        "    # ========================================\n",
        "    # MODE 1: PLANNING (no plan exists yet)\n",
        "    # ========================================\n",
        "    if not has_plan(state):\n",
        "        latest_message = get_latest_human_message(messages)\n",
        "        \n",
        "        if not latest_message:\n",
        "            return Command(\n",
        "                update={\"plan\": {\"steps\": [], \"plan_summary\": \"No query\"}},\n",
        "                goto=\"__end__\"\n",
        "            )\n",
        "        \n",
        "        try:\n",
        "            planning_chain = planning_prompt_template | supervisor_model\n",
        "            response = planning_chain.invoke({\"input\": latest_message})\n",
        "            content = response.content if hasattr(response, 'content') else str(response)\n",
        "            \n",
        "            # Parse JSON plan\n",
        "            if \"{\" in content and \"}\" in content:\n",
        "                start = content.find(\"{\")\n",
        "                end = content.rfind(\"}\") + 1\n",
        "                plan = json.loads(content[start:end])\n",
        "            else:\n",
        "                raise ValueError(\"No valid JSON found\")\n",
        "            \n",
        "            # Display clean plan summary\n",
        "            print(f\"\\n{'â”'*60}\")\n",
        "            print(\"ğŸ“‹ EXECUTION PLAN\")\n",
        "            print(f\"{'â”'*60}\")\n",
        "            print(f\"\\n{plan.get('plan_summary', 'N/A')}\")\n",
        "            print(f\"\\nğŸ“ Steps:\")\n",
        "            for step in plan.get(\"steps\", []):\n",
        "                print(f\"   {step.get('step_number')}. {step.get('agent')} - {step.get('purpose', 'N/A')[:60]}...\")\n",
        "            print(f\"{'â”'*60}\\n\")\n",
        "            \n",
        "            # Get first agent\n",
        "            first_step = plan.get(\"steps\", [{}])[0] if plan.get(\"steps\") else {}\n",
        "            first_agent = first_step.get(\"agent\", \"CONTENT_AGENT\")\n",
        "            \n",
        "            return Command(\n",
        "                update={\"plan\": plan, \"current_step\": 0},\n",
        "                goto=first_agent\n",
        "            )\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Planning error: {e}\")\n",
        "            fallback_plan = {\n",
        "                \"plan_summary\": \"Direct query routing (planning failed)\",\n",
        "                \"steps\": [{\"step_number\": 1, \"agent\": \"CONTENT_AGENT\", \"purpose\": \"Handle query\"}],\n",
        "                \"combination_strategy\": \"Present agent response directly\"\n",
        "            }\n",
        "            return Command(\n",
        "                update={\"plan\": fallback_plan, \"current_step\": 0},\n",
        "                goto=\"CONTENT_AGENT\"\n",
        "            )\n",
        "    \n",
        "    # ========================================\n",
        "    # MODE 2: SYNTHESIS (plan complete)\n",
        "    # ========================================\n",
        "    if is_plan_complete(state):\n",
        "        original_question = get_latest_human_message(messages)\n",
        "        agent_outputs = get_all_agent_outputs(messages)\n",
        "        \n",
        "        print(f\"ğŸ“Š Synthesizing results from {len(agent_outputs)} agent(s)...\")\n",
        "        \n",
        "        try:\n",
        "            formatted_outputs = format_agent_outputs_for_synthesis(agent_outputs, plan)\n",
        "            \n",
        "            synthesis_chain = synthesis_prompt_template | supervisor_model\n",
        "            response = synthesis_chain.invoke({\n",
        "                \"question\": original_question,\n",
        "                \"plan_summary\": plan.get(\"plan_summary\", \"\"),\n",
        "                \"step_dependencies\": plan.get(\"step_dependencies\", \"No dependencies specified\"),\n",
        "                \"combination_strategy\": plan.get(\"combination_strategy\", \"\"),\n",
        "                \"expected_final_output\": plan.get(\"expected_final_output\", \"Comprehensive analysis\"),\n",
        "                \"agent_outputs\": formatted_outputs\n",
        "            })\n",
        "            \n",
        "            content = response.content if hasattr(response, 'content') else str(response)\n",
        "            print(f\"âœ… Analysis complete\\n\")\n",
        "            \n",
        "            return Command(\n",
        "                update={\"messages\": [AIMessage(content=content, name=\"supervisor\")]},\n",
        "                goto=\"__end__\"\n",
        "            )\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Synthesis error: {e}\")\n",
        "            raw_outputs = \"\\n\\n\".join([f\"**{k}**:\\n{v[:2000]}\" for k, v in agent_outputs.items()])\n",
        "            return Command(\n",
        "                update={\"messages\": [AIMessage(content=f\"Analysis completed:\\n\\n{raw_outputs}\", name=\"supervisor\")]},\n",
        "                goto=\"__end__\"\n",
        "            )\n",
        "    \n",
        "    # ========================================\n",
        "    # MODE 3: EXECUTION (route to next agent with LLM-extracted context)\n",
        "    # ========================================\n",
        "    current_step = get_current_step(state)\n",
        "    \n",
        "    if current_step:\n",
        "        agent_name = current_step.get(\"agent\")\n",
        "        \n",
        "        # Use LLM to extract relevant context from previous agent\n",
        "        context = extract_context_for_next_agent(messages, current_step, supervisor_model)\n",
        "        if context:\n",
        "            print(f\"   ğŸ“ Context for {agent_name}: {context[:100]}...\")\n",
        "            updated_plan = plan.copy()\n",
        "            updated_plan[\"steps\"][current_step_idx][\"input_context\"] = context\n",
        "            return Command(\n",
        "                update={\"plan\": updated_plan},\n",
        "                goto=agent_name\n",
        "            )\n",
        "        \n",
        "        return Command(goto=agent_name)\n",
        "    \n",
        "    return Command(goto=\"__end__\")\n",
        "\n",
        "print(\"âœ… supervisor_node() with LLM-based context extraction\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… content_agent_node() defined\n"
          ]
        }
      ],
      "source": [
        "def build_query_with_context(original_query: str, step: Dict) -> str:\n",
        "    \"\"\"Build query with context provided by supervisor.\"\"\"\n",
        "    context = step.get(\"input_context\", \"\")\n",
        "    if context:\n",
        "        return f\"{original_query}\\n\\nRelevant context from previous analysis:\\n{context}\"\n",
        "    return original_query\n",
        "\n",
        "\n",
        "def content_agent_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    \"\"\"Content Agent node - handles customer feedback and sentiment analysis.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    query = get_latest_human_message(messages)\n",
        "    current_step_idx = state.get(\"current_step\", 0)\n",
        "    \n",
        "    # Get context from supervisor if available\n",
        "    current_step = get_current_step(state)\n",
        "    enhanced_query = build_query_with_context(query, current_step) if current_step else query\n",
        "    \n",
        "    print(f\"ğŸ” CONTENT_AGENT analyzing...\")\n",
        "    \n",
        "    try:\n",
        "        result = content_agent.invoke(enhanced_query)\n",
        "        response_content = result.get(\"output\", \"\")\n",
        "        print(f\"   âœ“ Complete\")\n",
        "        \n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=response_content, name=\"CONTENT_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   âœ— Error: {e}\")\n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=f\"Error: {str(e)}\", name=\"CONTENT_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "\n",
        "print(\"âœ… content_agent_node() defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… data_analyst_agent_node() defined\n"
          ]
        }
      ],
      "source": [
        "def data_analyst_agent_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    \"\"\"Data Analyst Agent node - handles metrics and analytics queries.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    original_query = get_latest_human_message(messages)\n",
        "    current_step_idx = state.get(\"current_step\", 0)\n",
        "    \n",
        "    # Get context from supervisor if available\n",
        "    current_step = get_current_step(state)\n",
        "    query = build_query_with_context(original_query, current_step) if current_step else original_query\n",
        "    \n",
        "    print(f\"ğŸ“Š DATA_ANALYST_AGENT analyzing...\")\n",
        "    \n",
        "    try:\n",
        "        chunks = []\n",
        "        for chunk in data_analyst_agent.stream(query):\n",
        "            chunks.append(str(chunk))\n",
        "        \n",
        "        response_parts = []\n",
        "        for chunk in chunks:\n",
        "            try:\n",
        "                chunk_data = json.loads(chunk)\n",
        "                if isinstance(chunk_data, dict):\n",
        "                    if chunk_data.get(\"type\") == \"text\":\n",
        "                        response_parts.append(chunk_data.get(\"text\", \"\"))\n",
        "                    elif \"content\" in chunk_data:\n",
        "                        response_parts.append(str(chunk_data.get(\"content\", \"\")))\n",
        "                    elif \"message\" in chunk_data:\n",
        "                        response_parts.append(f\"Agent error: {chunk_data.get('message', '')}\")\n",
        "                else:\n",
        "                    response_parts.append(str(chunk_data))\n",
        "            except (json.JSONDecodeError, TypeError):\n",
        "                response_parts.append(chunk)\n",
        "        \n",
        "        response_content = \"\".join(response_parts)\n",
        "        print(f\"   âœ“ Complete\")\n",
        "        \n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=response_content, name=\"DATA_ANALYST_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   âœ— Error: {e}\")\n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=f\"Error: {str(e)}\", name=\"DATA_ANALYST_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "\n",
        "print(\"âœ… data_analyst_agent_node() defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… research_agent_node() defined\n"
          ]
        }
      ],
      "source": [
        "def research_agent_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    \"\"\"Research Agent node - handles market and strategic analysis.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    original_query = get_latest_human_message(messages)\n",
        "    current_step_idx = state.get(\"current_step\", 0)\n",
        "    \n",
        "    # Get context from supervisor if available\n",
        "    current_step = get_current_step(state)\n",
        "    query = build_query_with_context(original_query, current_step) if current_step else original_query\n",
        "    \n",
        "    print(f\"ğŸ”¬ RESEARCH_AGENT analyzing...\")\n",
        "    \n",
        "    try:\n",
        "        chunks = []\n",
        "        for chunk in research_agent.stream(query):\n",
        "            chunks.append(str(chunk))\n",
        "        \n",
        "        response_parts = []\n",
        "        for chunk in chunks:\n",
        "            try:\n",
        "                chunk_data = json.loads(chunk)\n",
        "                if isinstance(chunk_data, dict):\n",
        "                    if chunk_data.get(\"type\") == \"text\":\n",
        "                        response_parts.append(chunk_data.get(\"text\", \"\"))\n",
        "                    elif \"content\" in chunk_data:\n",
        "                        response_parts.append(str(chunk_data.get(\"content\", \"\")))\n",
        "                    elif \"message\" in chunk_data:\n",
        "                        response_parts.append(f\"Agent error: {chunk_data.get('message', '')}\")\n",
        "                else:\n",
        "                    response_parts.append(str(chunk_data))\n",
        "            except (json.JSONDecodeError, TypeError):\n",
        "                response_parts.append(chunk)\n",
        "        \n",
        "        response_content = \"\".join(response_parts)\n",
        "        print(f\"   âœ“ Complete\")\n",
        "        \n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=response_content, name=\"RESEARCH_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   âœ— Error: {e}\")\n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=f\"Error: {str(e)}\", name=\"RESEARCH_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "\n",
        "print(\"âœ… research_agent_node() defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Create the Routing Function\n",
        "\n",
        "The **routing function** is used by LangGraph's conditional edges. It:\n",
        "1. Reads the supervisor's routing decision (JSON)\n",
        "2. Parses the `next_agent` field\n",
        "3. Returns the name of the next node to execute\n",
        "\n",
        "This enables dynamic routing based on the supervisor's analysis of each query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Routing configured with edges\n"
          ]
        }
      ],
      "source": [
        "# Routing logic is now defined with edges in the graph setup cell\n",
        "print(\"âœ… Routing configured with edges\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Build the Workflow Graph\n",
        "\n",
        "Now we assemble all the pieces into a **StateGraph**. The graph defines:\n",
        "\n",
        "1. **Nodes**: The processing units (supervisor + 3 agents)\n",
        "2. **Edges**: The connections between nodes\n",
        "3. **Conditional Edges**: Dynamic routing based on state\n",
        "\n",
        "### Graph Structure:\n",
        "```\n",
        "START \n",
        "  â†“\n",
        "supervisor (routing)\n",
        "  â†“ (conditional)\n",
        "  â”œâ”€â”€ CONTENT_AGENT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "  â”œâ”€â”€ DATA_ANALYST_AGENT â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€ supervisor (synthesis)\n",
        "  â””â”€â”€ RESEARCH_AGENT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â†“\n",
        "                                       END\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… StateGraph created\n",
            "   Added node: supervisor\n",
            "   Added node: CONTENT_AGENT\n",
            "   Added node: DATA_ANALYST_AGENT\n",
            "   Added node: RESEARCH_AGENT\n"
          ]
        }
      ],
      "source": [
        "# Create the StateGraph with our State type\n",
        "workflow = StateGraph(State)\n",
        "print(\"âœ… StateGraph created\")\n",
        "\n",
        "# Add the supervisor node\n",
        "workflow.add_node(\"supervisor\", supervisor_node)\n",
        "print(\"   Added node: supervisor\")\n",
        "\n",
        "# Add the agent nodes\n",
        "workflow.add_node(\"CONTENT_AGENT\", content_agent_node)\n",
        "print(\"   Added node: CONTENT_AGENT\")\n",
        "\n",
        "workflow.add_node(\"DATA_ANALYST_AGENT\", data_analyst_agent_node)\n",
        "print(\"   Added node: DATA_ANALYST_AGENT\")\n",
        "\n",
        "workflow.add_node(\"RESEARCH_AGENT\", research_agent_node)\n",
        "print(\"   Added node: RESEARCH_AGENT\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Graph edges configured\n",
            "   Entry: START â†’ supervisor\n",
            "   Routing: Handled by Command.goto in each node\n"
          ]
        }
      ],
      "source": [
        "# Define the graph edges\n",
        "# With Command routing, nodes specify their own destinations via goto\n",
        "\n",
        "# Only need the entry point - Command handles all other routing\n",
        "workflow.add_edge(START, \"supervisor\")\n",
        "\n",
        "print(\"âœ… Graph edges configured\")\n",
        "print(\"   Entry: START â†’ supervisor\")\n",
        "print(\"   Routing: Handled by Command.goto in each node\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Compile the Workflow\n",
        "\n",
        "Compiling the graph creates an executable application. The compiled graph:\n",
        "- Validates the graph structure\n",
        "- Creates an optimized execution plan\n",
        "- Returns a runnable object that can be invoked with input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Workflow compiled successfully!\n",
            "\n",
            "ğŸ“Š Workflow Summary:\n",
            "   â€¢ 1 Supervisor node with 3 modes: Planning, Execution, Synthesis\n",
            "   â€¢ 3 Specialized agent nodes with plan-aware context\n",
            "   â€¢ Dynamic multi-step execution based on explicit plan\n",
            "   â€¢ Flow: START â†’ supervisor(plan) â†’ supervisor(exec) â†’ agents... â†’ supervisor(synth) â†’ END\n",
            "\n",
            "ğŸ“‹ Planning Features:\n",
            "   â€¢ Creates explicit execution plan with agent assignments\n",
            "   â€¢ Specifies purpose and expected output for each agent\n",
            "   â€¢ Defines combination strategy for synthesizing results\n",
            "   â€¢ Supports single or multi-agent plans based on query complexity\n"
          ]
        }
      ],
      "source": [
        "# Compile the workflow into an executable application\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"âœ… Workflow compiled successfully!\")\n",
        "print(\"\\nğŸ“Š Workflow Summary:\")\n",
        "print(\"   â€¢ 1 Supervisor node with 3 modes: Planning, Execution, Synthesis\")\n",
        "print(\"   â€¢ 3 Specialized agent nodes with plan-aware context\")\n",
        "print(\"   â€¢ Dynamic multi-step execution based on explicit plan\")\n",
        "print(\"   â€¢ Flow: START â†’ supervisor(plan) â†’ supervisor(exec) â†’ agents... â†’ supervisor(synth) â†’ END\")\n",
        "print(\"\\nğŸ“‹ Planning Features:\")\n",
        "print(\"   â€¢ Creates explicit execution plan with agent assignments\")\n",
        "print(\"   â€¢ Specifies purpose and expected output for each agent\")\n",
        "print(\"   â€¢ Defines combination strategy for synthesizing results\")\n",
        "print(\"   â€¢ Supports single or multi-agent plans based on query complexity\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Visualize the Graph (Optional)\n",
        "\n",
        "LangGraph can generate a visual representation of the workflow. This requires the `pygraphviz` or `grandalf` library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Graph visualization generated\n"
          ]
        }
      ],
      "source": [
        "# Try to visualize the graph (requires graphviz)\n",
        "try:\n",
        "    from IPython.display import Image, display\n",
        "    \n",
        "    # Generate the graph visualization\n",
        "    graph_image = app.get_graph().draw_mermaid_png()\n",
        "    display(Image(graph_image))\n",
        "    print(\"âœ… Graph visualization generated\")\n",
        "except Exception as e:\n",
        "    print(f\"â„¹ï¸ Graph visualization not available: {e}\")\n",
        "    print(\"   Install pygraphviz or grandalf for visualization support\")\n",
        "    print(\"\\n   Graph structure:\")\n",
        "    print(\"   START â†’ supervisor â†’ [CONTENT_AGENT | DATA_ANALYST_AGENT | RESEARCH_AGENT] â†’ supervisor â†’ END\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Test the Workflow\n",
        "\n",
        "Now let's test the workflow with some sample queries! Each query type should be routed to a different agent:\n",
        "\n",
        "| Query Type | Expected Agent |\n",
        "|------------|----------------|\n",
        "| Customer feedback, sentiment, complaints | CONTENT_AGENT |\n",
        "| Metrics, behavior, churn, analytics | DATA_ANALYST_AGENT |\n",
        "| Market research, competition, strategy | RESEARCH_AGENT |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/langgraph_snowflake/lib/python3.11/site-packages/munch/__init__.py:24: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… TruLens dependencies imported successfully!\n"
          ]
        }
      ],
      "source": [
        "from trulens.apps.langgraph import TruGraph\n",
        "from trulens.connectors.snowflake import SnowflakeConnector\n",
        "from trulens.providers.cortex import Cortex\n",
        "from trulens.core.feedback.custom_metric import MetricConfig\n",
        "from trulens.core.feedback.selector import Selector\n",
        "from trulens.core.run import Run, RunConfig\n",
        "from functools import partial\n",
        "import uuid\n",
        "\n",
        "print(\"âœ… TruLens dependencies imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running the TruLens dashboard requires providing a `password` to the `SnowflakeConnector`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Snowflake connector created for TruLens\n",
            "âœ… Cortex evaluation provider initialized\n",
            "   Model: openai-gpt-5\n"
          ]
        }
      ],
      "source": [
        "# Connect TruLens to Snowflake for observability\n",
        "# This uses the same session we created earlier\n",
        "\n",
        "sf_connector = SnowflakeConnector(snowpark_session=session)\n",
        "print(\"âœ… Snowflake connector created for TruLens\")\n",
        "\n",
        "# Initialize the Cortex provider for client-side evaluations\n",
        "# This provider will use Snowflake Cortex LLMs to compute custom metrics\n",
        "trace_eval_provider = Cortex(\n",
        "    model_engine=\"openai-gpt-5\",\n",
        "    snowpark_session=session\n",
        ")\n",
        "print(\"âœ… Cortex evaluation provider initialized\")\n",
        "print(f\"   Model: openai-gpt-5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Plan Quality metric configured\n",
            "âœ… Plan Adherence metric configured\n",
            "âœ… Execution Efficiency metric configured\n",
            "âœ… Logical Consistency metric configured\n"
          ]
        }
      ],
      "source": [
        "# Plan Quality - Evaluates how well the supervisor creates execution plans\n",
        "f_plan_quality = MetricConfig(\n",
        "    metric_implementation=partial(\n",
        "        trace_eval_provider.plan_quality_with_cot_reasons,\n",
        "        # enable_trace_compression=False\n",
        "    ),\n",
        "    metric_name=\"Plan Quality\",\n",
        "    selectors={\n",
        "        \"trace\": Selector(trace_level=True),\n",
        "    },\n",
        ")\n",
        "print(\"âœ… Plan Quality metric configured\")\n",
        "\n",
        "# Plan Adherence - Checks if the agent follows the execution plan\n",
        "f_plan_adherence = MetricConfig(\n",
        "    metric_implementation=partial(\n",
        "        trace_eval_provider.plan_adherence_with_cot_reasons,\n",
        "        # enable_trace_compression=False\n",
        "    ),\n",
        "    metric_name=\"Plan Adherence\",\n",
        "    selectors={\n",
        "        \"trace\": Selector(trace_level=True),\n",
        "    },\n",
        ")\n",
        "print(\"âœ… Plan Adherence metric configured\")\n",
        "\n",
        "# Execution Efficiency - Measures workflow efficiency\n",
        "f_execution_efficiency = MetricConfig(\n",
        "    metric_implementation=partial(\n",
        "        trace_eval_provider.execution_efficiency_with_cot_reasons,\n",
        "        # enable_trace_compression=False\n",
        "    ),\n",
        "    metric_name=\"Execution Efficiency\",\n",
        "    selectors={\n",
        "        \"trace\": Selector(trace_level=True),\n",
        "    },\n",
        ")\n",
        "print(\"âœ… Execution Efficiency metric configured\")\n",
        "\n",
        "# Logical Consistency - Verifies consistency across agent responses\n",
        "f_logical_consistency = MetricConfig(\n",
        "    metric_implementation=partial(\n",
        "        trace_eval_provider.logical_consistency_with_cot_reasons,\n",
        "        # enable_trace_compression=False\n",
        "    ),\n",
        "    metric_name=\"Logical Consistency\",\n",
        "    selectors={\n",
        "        \"trace\": Selector(trace_level=True),\n",
        "    },\n",
        ")\n",
        "print(\"âœ… Logical Consistency metric configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 14: Instrument with TruLens and Run Evaluation\n",
        "\n",
        "Now we wrap the LangGraph application directly with `TruGraph` and run evaluation with full LangGraph input states.\n",
        "\n",
        "The evaluation dataset contains actual LangGraph state dicts (with `messages` key) that are passed directly to `graph.invoke()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… experimental Feature.OTEL_TRACING enabled.\n",
            "ğŸ”’ experimental Feature.OTEL_TRACING is enabled and cannot be changed.\n",
            "instrumenting <class 'langgraph.graph.state.StateGraph'> for base <class 'langgraph.graph.state.StateGraph'>\n",
            "instrumenting <class 'langgraph.graph.state.CompiledStateGraph'> for base <class 'langgraph.graph.state.CompiledStateGraph'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "\tinstrumenting astream_events\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "\tinstrumenting stream_mode\n",
            "instrumenting <class 'langgraph.graph.state.CompiledStateGraph'> for base <class 'langgraph.pregel.main.Pregel'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "\tinstrumenting astream_events\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "\tinstrumenting stream_mode\n",
            "âœ… TruGraph instrumented app created\n",
            "   App Name: Customer Intelligence Multi-Agent f5beb73f\n",
            "   App Version: V1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluator thread encountered an error: 'str' object has no attribute 'get'\n"
          ]
        }
      ],
      "source": [
        "# Generate unique app name and version\n",
        "APP_NAME = f\"Customer Intelligence Multi-Agent\"\n",
        "APP_VERSION = f\"V{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "# Directly wrap the LangGraph graph with TruGraph\n",
        "tru_app = TruGraph(\n",
        "    app,  # The compiled StateGraph from Step 11\n",
        "    app_name=APP_NAME,\n",
        "    app_version=APP_VERSION,\n",
        "    main_method=app.invoke,  # Use graph's invoke method directly\n",
        "    connector=sf_connector,\n",
        ")\n",
        "\n",
        "print(f\"âœ… TruGraph instrumented app created\")\n",
        "print(f\"   App Name: {APP_NAME}\")\n",
        "print(f\"   App Version: {APP_VERSION}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define all metrics to compute (server-side + client-side)\n",
        "metrics_to_compute = [\n",
        "    # Server-side metrics\n",
        "    \"answer_relevance\",\n",
        "    # Client-side metrics\n",
        "    f_plan_quality,\n",
        "    f_plan_adherence,\n",
        "    f_execution_efficiency,\n",
        "    f_logical_consistency,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "Congratulations! ğŸ‰ You've successfully built a **multi-agent supervisor workflow with explicit planning** using LangGraph and Snowflake Cortex. Here's what we accomplished:\n",
        "\n",
        "### Key Components Built:\n",
        "\n",
        "1. **Extended State Management**: Custom state with `messages`, `execution_plan`, and `current_step` tracking\n",
        "2. **Supervisor Model**: `ChatSnowflake` for intelligent planning, execution, and synthesis\n",
        "3. **Specialized Agents**: Three `SnowflakeCortexAgent` instances with plan-aware context\n",
        "4. **Prompt Engineering**: Created planning, routing, and synthesis prompts\n",
        "5. **Node Functions**: Implemented supervisor with 3 modes and plan-aware agent nodes\n",
        "6. **Graph Structure**: Connected nodes with conditional routing based on execution plan\n",
        "\n",
        "### Architecture Pattern with Planning:\n",
        "\n",
        "```\n",
        "User Query â†’ Supervisor (Plan) â†’ Supervisor (Execute) â†’ Agent(s)... â†’ Supervisor (Synthesize) â†’ Executive Summary\n",
        "```\n",
        "\n",
        "### Planning Features:\n",
        "\n",
        "The supervisor now creates an **explicit execution plan** that includes:\n",
        "- **Agent Selection**: Which specialized agents to call and in what order\n",
        "- **Purpose Specification**: Why each agent is being called\n",
        "- **Expected Outputs**: What each agent should deliver\n",
        "- **Combination Strategy**: How to synthesize all results into a cohesive answer\n",
        "\n",
        "This planning approach provides:\n",
        "- **Transparency**: Clear visibility into the decision-making process\n",
        "- **Flexibility**: Support for single or multi-agent plans based on query complexity\n",
        "- **Context-Aware Execution**: Agents receive focused context from the plan\n",
        "- **Structured Synthesis**: Results combined according to a defined strategy\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "- **Add more agents**: Extend the workflow with additional specialized agents\n",
        "- **Implement memory**: Add conversation persistence with LangGraph checkpointers\n",
        "- **Add human-in-the-loop**: Include plan approval steps for critical decisions\n",
        "- **Deploy to production**: Use LangGraph Cloud or LangGraph Studio for deployment\n",
        "\n",
        "### Resources:\n",
        "\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
        "- [Snowflake Cortex Documentation](https://docs.snowflake.com/en/user-guide/snowflake-cortex)\n",
        "- [LangChain Snowflake Integration](https://python.langchain.com/docs/integrations/providers/snowflake)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define evaluation inputs as full LangGraph state dicts\n",
        "# This passes the actual state that LangGraph expects directly to graph.invoke()\n",
        "evaluation_inputs = [\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"Assess the churn risk for customers complaining about API issues.\")],\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"What industries have the highest customer lifetime value and represent our best strategic expansion opportunities?\")],\n",
        "    },\n",
        "]\n",
        "\n",
        "# Create DataFrame with the state dicts\n",
        "queries_df = pd.DataFrame({\"input_state\": evaluation_inputs})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Run configuration created\n",
            "   Run Name: customer_intel_eval_e3e49255\n",
            "   Dataset: customer_intelligence_queries\n",
            "   Source: DataFrame with 1 input states\n",
            "\n",
            "âœ… Run added to TruGraph app\n"
          ]
        }
      ],
      "source": [
        "# Create unique run name\n",
        "run_name = f\"customer_intel_eval_{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "# Configure the evaluation run\n",
        "# The dataset_spec maps to the column containing full LangGraph state dicts\n",
        "run_config = RunConfig(\n",
        "    run_name=run_name,\n",
        "    dataset_name=\"customer_intelligence_queries\",\n",
        "    source_type=\"DATAFRAME\",\n",
        "    dataset_spec={\"RECORD_ROOT.INPUT\": \"input_state\"},  # Maps to state dict column\n",
        ")\n",
        "\n",
        "print(f\"âœ… Run configuration created\")\n",
        "print(f\"   Run Name: {run_name}\")\n",
        "print(f\"   Dataset: customer_intelligence_queries\")\n",
        "print(f\"   Source: DataFrame with {len(queries_df)} input states\")\n",
        "\n",
        "# Add the run to the instrumented app\n",
        "run: Run = tru_app.add_run(run_config=run_config)\n",
        "print(f\"\\nâœ… Run added to TruGraph app\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸš€ Starting evaluation run...\n",
            "   Processing 1 queries through the multi-agent workflow\n",
            "\n",
            "\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ğŸ“‹ EXECUTION PLAN\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "CONTENT_AGENT will use cortex_search on SUPPORT_TICKETS to find API-related complaints, then DATA_ANALYST_AGENT will use cortex_analyst to query CUSTOMER_METRICS for churn risk indicators\n",
            "\n",
            "ğŸ“ Steps:\n",
            "   1. CONTENT_AGENT - Identify support tickets containing API-related complaints a...\n",
            "   2. DATA_ANALYST_AGENT - Retrieve comprehensive churn risk metrics for customers iden...\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "ğŸ” CONTENT_AGENT analyzing...\n",
            "   âœ“ Complete\n",
            "   ğŸ“ Context for DATA_ANALYST_AGENT: The search identified four ticket IDs with API-related complaints: TKT_00001637, TKT_00001846, TKT_0...\n",
            "ğŸ“Š DATA_ANALYST_AGENT analyzing...\n",
            "   âœ“ Complete\n",
            "ğŸ“Š Synthesizing results from 2 agent(s)...\n",
            "âœ… Analysis complete\n",
            "\n",
            "âœ… Run started!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nğŸš€ Starting evaluation run...\")\n",
        "print(f\"   Processing {len(queries_df)} queries through the multi-agent workflow\\n\")\n",
        "\n",
        "run.start(input_df=queries_df)\n",
        "\n",
        "print(\"âœ… Run started!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â³ Waiting for invocations to complete...\n",
            "   Initial Status: RunStatus.CREATED\n",
            "\n",
            "âœ… Final Status: RunStatus.INVOCATION_COMPLETED\n",
            "   All invocations completed successfully!\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# ============================================\n",
        "# Wait for invocations to complete\n",
        "# ============================================\n",
        "print(\"â³ Waiting for invocations to complete...\")\n",
        "print(f\"   Initial Status: {run.get_status()}\")\n",
        "\n",
        "wait_count = 0\n",
        "max_wait = 60  # Max 5 minutes (60 * 5 seconds)\n",
        "\n",
        "while run.get_status() != \"INVOCATION_COMPLETED\" and wait_count < max_wait:\n",
        "    time.sleep(5)\n",
        "    wait_count += 1\n",
        "    status = run.get_status()\n",
        "    if wait_count % 6 == 0:  # Print status every 30 seconds\n",
        "        print(f\"   [{wait_count * 5}s] Status: {status}\")\n",
        "\n",
        "final_status = run.get_status()\n",
        "print(f\"\\nâœ… Final Status: {final_status}\")\n",
        "\n",
        "if final_status == \"INVOCATION_COMPLETED\":\n",
        "    print(\"   All invocations completed successfully!\")\n",
        "else:\n",
        "    print(f\"   âš ï¸ Run did not complete. Current status: {final_status}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unrecognized Cortex response format. It did not have usage information:\n",
            "{'error': {'message': 'json mode output validation error: unexpected end of '\n",
            "                      'JSON input',\n",
            "           'request_id': '3400689e-8dfa-48c2-bbe5-c5e9f90e9fd9'}}\n",
            "Unrecognized Cortex response format. It did not have usage information:\n",
            "{'error': {'message': 'json mode output validation error: unexpected end of '\n",
            "                      'JSON input',\n",
            "           'request_id': '3400689e-8dfa-48c2-bbe5-c5e9f90e9fd9'}}\n",
            "CortexEndpoint request failed <class 'snowflake.cortex._complete.MidStreamException'>= (Request ID: None). Retries remaining=3.\n",
            "Unrecognized Cortex response format. It did not have usage information:\n",
            "{'error': {'message': 'json mode output validation error: unexpected end of '\n",
            "                      'JSON input',\n",
            "           'request_id': '20f636ae-88f0-486e-ae01-2dce35575248'}}\n",
            "Unrecognized Cortex response format. It did not have usage information:\n",
            "{'error': {'message': 'json mode output validation error: unexpected end of '\n",
            "                      'JSON input',\n",
            "           'request_id': '20f636ae-88f0-486e-ae01-2dce35575248'}}\n",
            "CortexEndpoint request failed <class 'snowflake.cortex._complete.MidStreamException'>= (Request ID: None). Retries remaining=2.\n",
            "Unrecognized Cortex response format. It did not have usage information:\n",
            "{'error': {'message': 'json mode output validation error: unexpected end of '\n",
            "                      'JSON input',\n",
            "           'request_id': '42800516-6694-4645-af16-4a597efc38ff'}}\n",
            "Unrecognized Cortex response format. It did not have usage information:\n",
            "{'error': {'message': 'json mode output validation error: unexpected end of '\n",
            "                      'JSON input',\n",
            "           'request_id': '42800516-6694-4645-af16-4a597efc38ff'}}\n",
            "CortexEndpoint request failed <class 'snowflake.cortex._complete.MidStreamException'>= (Request ID: None). Retries remaining=1.\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Compute evaluation metrics\n",
        "# ============================================\n",
        "run.compute_metrics(metrics_to_compute)\n",
        "\n",
        "print(\"âœ… Metrics computation initiated!\")\n",
        "print(f\"   Current Status: {run.get_status()}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langgraph_snowflake",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
