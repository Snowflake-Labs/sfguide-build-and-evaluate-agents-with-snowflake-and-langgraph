{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building a Multi-Agent Supervisor Workflow with LangGraph and Snowflake\n",
        "\n",
        "This notebook demonstrates how to build a **multi-agent supervisor architecture** using LangGraph and Snowflake Cortex Agents. The workflow consists of:\n",
        "\n",
        "- **Supervisor**: An AI coordinator that routes queries to specialized agents and synthesizes their responses\n",
        "- **Content Agent**: Handles customer feedback, sentiment analysis, and communication intelligence\n",
        "- **Data Analyst Agent**: Handles customer behavior, business metrics, and predictive analytics\n",
        "- **Research Agent**: Handles market intelligence, strategic analysis, and competitive insights\n",
        "\n",
        "## Architecture Overview\n",
        "\n",
        "```\n",
        "START ‚Üí Supervisor (Route) ‚Üí Specialized Agent ‚Üí Supervisor (Synthesize) ‚Üí END\n",
        "```\n",
        "\n",
        "The supervisor makes two passes:\n",
        "1. **Routing Pass**: Analyzes the query and routes to the appropriate agent\n",
        "2. **Synthesis Pass**: Combines agent output into an executive summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install and Import Dependencies\n",
        "\n",
        "First, let's import all the necessary libraries. We'll need:\n",
        "- **LangChain Core**: For message types and prompt templates\n",
        "- **LangChain Snowflake**: For Snowflake-specific integrations (ChatSnowflake, SnowflakeCortexAgent)\n",
        "- **LangGraph**: For building the stateful workflow graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports loaded successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/langgraph_snowflake/lib/python3.11/site-packages/langchain_snowflake/chat_models/base.py:26: UserWarning: Field name \"schema\" in \"ChatSnowflake\" shadows an attribute in parent \"BaseChatModel\"\n",
            "  class ChatSnowflake(\n"
          ]
        }
      ],
      "source": [
        "# LangGraph imports\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.types import Command\n",
        "from langgraph.graph.message import MessagesState\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Fix for langchain_snowflake import compatibility issue\n",
        "# Tool class moved from langchain.tools to langchain_core.tools in newer LangChain\n",
        "import langchain.tools\n",
        "from langchain_core.tools import Tool\n",
        "langchain.tools.Tool = Tool  # Shim for backwards compatibility\n",
        "\n",
        "# Snowflake imports\n",
        "from langchain_snowflake import ChatSnowflake, SnowflakeCortexAgent, create_session_from_env\n",
        "from snowflake.snowpark import Session\n",
        "\n",
        "# Utility imports\n",
        "import json\n",
        "import os\n",
        "from typing import Dict, List, Optional, Literal\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "print(\"‚úÖ All imports loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Define the Workflow State\n",
        "\n",
        "LangGraph uses a **state** object that flows through the graph. We'll use the built-in `MessagesState` which provides:\n",
        "- A `messages` list that accumulates all messages in the conversation\n",
        "- Automatic message deduplication and ordering\n",
        "\n",
        "The state is shared across all nodes and gets updated as the workflow progresses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ State defined with efficiency optimizations\n"
          ]
        }
      ],
      "source": [
        "# Extend MessagesState to include execution plan tracking\n",
        "class State(MessagesState):\n",
        "    \"\"\"Extended state that tracks execution plan and progress.\n",
        "    \n",
        "    Designed for efficient single-pass execution:\n",
        "    - Plan is created ONCE and never modified during execution\n",
        "    - Agents chain directly to each other without supervisor re-entry\n",
        "    - Errors are aggregated, not cascaded\n",
        "    \"\"\"\n",
        "    plan: Optional[Dict] = None  # The supervisor's explicit plan (immutable after creation)\n",
        "    current_step: int = 0  # Current step being executed in the plan\n",
        "    agent_outputs: Dict = {}  # Accumulated outputs from all agents (avoids message parsing)\n",
        "    execution_errors: List = []  # Aggregated errors (not per-chunk)\n",
        "    planning_complete: bool = False  # Flag to skip re-planning\n",
        "    \n",
        "print(\"‚úÖ State defined with efficiency optimizations\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Snowflake Session\n",
        "\n",
        "We need to establish a connection to Snowflake. The `create_session_from_env()` function reads credentials from environment variables:\n",
        "- `SNOWFLAKE_ACCOUNT`\n",
        "- `SNOWFLAKE_USER`\n",
        "- `SNOWFLAKE_PASSWORD`\n",
        "- `SNOWFLAKE_DATABASE`\n",
        "- `SNOWFLAKE_SCHEMA`\n",
        "- `SNOWFLAKE_WAREHOUSE`\n",
        "\n",
        "Make sure you have a `.env` file with these variables set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Snowflake session created successfully!\n",
            "   Database: CUSTOMER_INTELLIGENCE_DB\n",
            "   Schema: PUBLIC\n",
            "   Warehouse: COMPUTE_WH\n"
          ]
        }
      ],
      "source": [
        "# Create Snowflake session from environment variables\n",
        "try:\n",
        "    session = create_session_from_env()\n",
        "    \n",
        "    # Get database and schema, stripping any quotes that Snowflake might add\n",
        "    current_database = session.get_current_database().strip('\"')\n",
        "    current_schema = session.get_current_schema().strip('\"')\n",
        "    \n",
        "    # IMPORTANT: Ensure warehouse is set - required for Cortex Analyst tools\n",
        "    warehouse = os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH')\n",
        "    session.sql(f\"USE WAREHOUSE {warehouse}\").collect()\n",
        "    current_warehouse = session.get_current_warehouse()\n",
        "    if current_warehouse:\n",
        "        current_warehouse = current_warehouse.strip('\"')\n",
        "    \n",
        "    print(\"‚úÖ Snowflake session created successfully!\")\n",
        "    print(f\"   Database: {current_database}\")\n",
        "    print(f\"   Schema: {current_schema}\")\n",
        "    print(f\"   Warehouse: {current_warehouse}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Snowflake connection failed: {e}\")\n",
        "    print(\"   Please check your .env file and Snowflake credentials\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Initialize the Supervisor Model\n",
        "\n",
        "The **Supervisor** is the brain of our multi-agent system. It uses Snowflake's Cortex LLM service (`ChatSnowflake`) to:\n",
        "1. Analyze incoming queries\n",
        "2. Route them to the appropriate specialized agent\n",
        "3. Synthesize the agent's response into an executive summary\n",
        "\n",
        "We use `claude-4-sonnet` with low temperature (0.1) for consistent, deterministic routing decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Supervisor model initialized!\n",
            "   Model: claude-4-sonnet\n",
            "   Temperature: 0.1 (deterministic)\n",
            "   Max tokens: 2000\n"
          ]
        }
      ],
      "source": [
        "# Initialize the supervisor model using Snowflake Cortex\n",
        "supervisor_model = ChatSnowflake(\n",
        "    session=session,\n",
        "    model=\"claude-4-sonnet\",  # Claude 4 Sonnet via Snowflake Cortex\n",
        "    temperature=0.1,          # Low temperature for consistent routing\n",
        "    max_tokens=2000           # Limit response length\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Supervisor model initialized!\")\n",
        "print(f\"   Model: claude-4-sonnet\")\n",
        "print(f\"   Temperature: 0.1 (deterministic)\")\n",
        "print(f\"   Max tokens: 2000\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Initialize Specialized Cortex Agents\n",
        "\n",
        "Now we initialize our three specialized **Snowflake Cortex Agents**. These agents are pre-configured in Snowflake with access to specific tools, data sources, and instructions.\n",
        "\n",
        "Each agent is specialized for a different domain:\n",
        "| Agent | Specialization |\n",
        "|-------|----------------|\n",
        "| **CONTENT_AGENT** | Customer feedback, sentiment analysis, support tickets |\n",
        "| **DATA_ANALYST_AGENT** | Metrics, behavior patterns, churn prediction, analytics |\n",
        "| **RESEARCH_AGENT** | Market research, competitive analysis, strategic insights |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CONTENT_AGENT initialized\n",
            "‚úÖ DATA_ANALYST_AGENT initialized\n",
            "‚úÖ RESEARCH_AGENT initialized\n",
            "\n",
            "üìç All agents loaded from: SNOWFLAKE_INTELLIGENCE.AGENTS\n",
            "üìç Using warehouse: COMPUTE_WH\n"
          ]
        }
      ],
      "source": [
        "# Agent configuration - agents are stored in the SNOWFLAKE_INTELLIGENCE.AGENTS schema\n",
        "AGENT_DATABASE = \"SNOWFLAKE_INTELLIGENCE\"\n",
        "AGENT_SCHEMA = \"AGENTS\"\n",
        "AGENT_WAREHOUSE = os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH')\n",
        "\n",
        "# Initialize Content Agent - Customer feedback and sentiment specialist\n",
        "content_agent = SnowflakeCortexAgent(\n",
        "    session=session,\n",
        "    name=\"CONTENT_AGENT\",\n",
        "    database=AGENT_DATABASE,\n",
        "    schema=AGENT_SCHEMA,\n",
        "    warehouse=AGENT_WAREHOUSE,  # Required for tool execution\n",
        "    description=\"Customer feedback, sentiment analysis, and communication intelligence specialist\",\n",
        ")\n",
        "print(\"‚úÖ CONTENT_AGENT initialized\")\n",
        "\n",
        "# Initialize Data Analyst Agent - Metrics and analytics specialist\n",
        "data_analyst_agent = SnowflakeCortexAgent(\n",
        "    session=session,\n",
        "    name=\"DATA_ANALYST_AGENT\",\n",
        "    database=AGENT_DATABASE,\n",
        "    schema=AGENT_SCHEMA,\n",
        "    warehouse=AGENT_WAREHOUSE,  # Required for Cortex Analyst text-to-SQL\n",
        "    description=\"Customer behavior, business metrics, and predictive analytics specialist\",\n",
        ")\n",
        "print(\"‚úÖ DATA_ANALYST_AGENT initialized\")\n",
        "\n",
        "# Initialize Research Agent - Market intelligence specialist\n",
        "research_agent = SnowflakeCortexAgent(\n",
        "    session=session,\n",
        "    name=\"RESEARCH_AGENT\",\n",
        "    database=AGENT_DATABASE,\n",
        "    schema=AGENT_SCHEMA,\n",
        "    warehouse=AGENT_WAREHOUSE,  # Required for Cortex Analyst text-to-SQL\n",
        "    description=\"Market intelligence, strategic analysis, and competitive insights specialist\",\n",
        ")\n",
        "print(\"‚úÖ RESEARCH_AGENT initialized\")\n",
        "\n",
        "print(f\"\\nüìç All agents loaded from: {AGENT_DATABASE}.{AGENT_SCHEMA}\")\n",
        "print(f\"üìç Using warehouse: {AGENT_WAREHOUSE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Create Supervisor Prompts\n",
        "\n",
        "The supervisor uses two prompts depending on its current task:\n",
        "\n",
        "### 1. Planning Prompt\n",
        "Creates an **explicit, detailed execution plan** before any agents are called. This ensures transparency, accountability, and methodical execution. The plan includes:\n",
        "\n",
        "| Element | Description |\n",
        "|---------|-------------|\n",
        "| **Plan Summary** | Concise description of the analytical approach |\n",
        "| **Steps** | Ordered list of agent calls with detailed specifications |\n",
        "| **Step Dependencies** | How data flows between steps |\n",
        "| **Combination Strategy** | Methodology for synthesizing all results |\n",
        "| **Expected Final Output** | What the final deliverable must contain |\n",
        "\n",
        "Each step in the plan specifies:\n",
        "- **Agent**: Which specialized agent to call\n",
        "- **Purpose**: Why this agent is needed\n",
        "- **Tools to Use**: Specific tools (Cortex Search, Churn Model, etc.)\n",
        "- **Data Sources**: Tables and data to query\n",
        "- **Methodology**: Step-by-step approach for the agent\n",
        "- **Specific Queries**: Questions the agent must answer\n",
        "- **Metrics to Collect**: KPIs and data points to gather\n",
        "- **Expected Output**: What the agent should deliver\n",
        "- **Success Criteria**: How to verify the step succeeded\n",
        "- **Dependencies**: Which previous steps this depends on\n",
        "\n",
        "### 2. Synthesis Prompt\n",
        "Used after all agents complete to combine findings into a comprehensive executive summary. The synthesis:\n",
        "- Follows the combination strategy from the plan\n",
        "- Verifies success criteria for each step\n",
        "- Correlates findings across agents using step dependencies\n",
        "- Meets the expected final output requirements\n",
        "- Includes quantitative analysis, risk assessment, and prioritized recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Planning prompt updated - reflects actual agent tools and data sources\n"
          ]
        }
      ],
      "source": [
        "# Planning Prompt - Creates detailed, actionable execution plans\n",
        "# EFFICIENCY OPTIMIZATIONS:\n",
        "# - Emphasizes consolidated SQL queries (single aggregation vs multiple separate calls)\n",
        "# - Clear tool separation based on actual agent configuration\n",
        "# - Plan is created ONCE and executed linearly without re-planning\n",
        "planning_prompt = \"\"\"\n",
        "You are an Executive AI Assistant supervisor. Create DETAILED, ACTIONABLE execution plans.\n",
        "\n",
        "**CRITICAL EFFICIENCY RULES:**\n",
        "1. **ONE PLAN, ONE EXECUTION** - Create the plan once. It will NOT be modified during execution.\n",
        "2. **CONSOLIDATE QUERIES** - Use single SQL aggregations instead of multiple separate queries.\n",
        "   - BAD: Separate queries for COUNT, AVG, SUM, etc.\n",
        "   - GOOD: One query with SELECT COUNT(*), AVG(col), SUM(col), ... GROUP BY ...\n",
        "3. **MINIMIZE AGENT CALLS** - Only use multiple agents when their specialized tools are needed.\n",
        "4. **USE THE RIGHT TOOL** - Each agent has specific tools for specific purposes.\n",
        "\n",
        "**AVAILABLE AGENTS AND TOOLS:**\n",
        "\n",
        "| Agent | Tools | Data Access | Best For |\n",
        "|-------|-------|-------------|----------|\n",
        "| CONTENT_AGENT | CUSTOMER_FEEDBACK_SEARCH (cortex_search), CUSTOMER_CONTENT_ANALYZER (UDF) | SUPPORT_TICKETS_SEARCH index | Semantic search for complaints/feedback, sentiment analysis on specific customers |\n",
        "| DATA_ANALYST_AGENT | BUSINESS_INTELLIGENCE_ANALYST (cortex_analyst), CUSTOMER_BEHAVIOR_ANALYZER (UDF) | CUSTOMER_BEHAVIOR_ANALYST semantic view (CUSTOMERS, USAGE_EVENTS, SUPPORT_TICKETS, CHURN_EVENTS) | Usage patterns, churn analysis, engagement metrics, behavior trends |\n",
        "| RESEARCH_AGENT | STRATEGIC_MARKET_ANALYST (cortex_analyst), CUSTOMER_SEGMENT_INTELLIGENCE (UDF) | STRATEGIC_RESEARCH_ANALYST semantic view (CUSTOMERS, USAGE_EVENTS, SUPPORT_TICKETS, CHURN_EVENTS) | Market intelligence, industry analysis, revenue/CLV analysis, strategic insights |\n",
        "\n",
        "**KEY DATA FIELDS AVAILABLE:**\n",
        "- CUSTOMERS: customer_id, company_size, industry, plan_type, status, signup_date, monthly_revenue\n",
        "- USAGE_EVENTS: event_id, customer_id, feature_used, event_date, session_duration_minutes, actions_count\n",
        "- SUPPORT_TICKETS: ticket_id, customer_id, category, priority, status, created_date, resolution_time_hours, satisfaction_score\n",
        "- CHURN_EVENTS: churn_id, customer_id, churn_reason, churn_date, days_since_signup, final_monthly_revenue\n",
        "\n",
        "**AGENT SELECTION GUIDE:**\n",
        "- Need to SEARCH ticket text for specific issues ‚Üí CONTENT_AGENT (cortex_search)\n",
        "- Need to ANALYZE specific customers' sentiment ‚Üí CONTENT_AGENT (UDF)\n",
        "- Need aggregate BEHAVIOR metrics (usage, sessions, engagement) ‚Üí DATA_ANALYST_AGENT\n",
        "- Need STRATEGIC analysis (CLV, market share, industry trends) ‚Üí RESEARCH_AGENT\n",
        "- Need to analyze specific customer segments strategically ‚Üí RESEARCH_AGENT (UDF)\n",
        "\n",
        "**NEVER DO:**\n",
        "- Issue separate queries for each metric (consolidate into ONE query)\n",
        "- Re-plan or update the plan mid-execution\n",
        "- Use multiple agents when one can answer the question\n",
        "\n",
        "**JSON Response Format:**\n",
        "{{\n",
        "    \"plan_summary\": \"[AGENT(s)] will use [TOOL(s)] to query [DATA_SOURCE(s)] for [GOAL]\",\n",
        "    \"total_steps\": <number>,\n",
        "    \"steps\": [\n",
        "        {{\n",
        "            \"step_number\": 1,\n",
        "            \"agent\": \"AGENT_NAME\",\n",
        "            \"tool\": \"TOOL_NAME\",\n",
        "            \"data_source\": \"Semantic view or search index name\",\n",
        "            \"purpose\": \"Specific analytical task\",\n",
        "            \"consolidated_query\": \"SINGLE query/search that gets ALL needed data for this step\",\n",
        "            \"expected_output\": \"Specific columns/fields to return\",\n",
        "            \"uses_data_from\": [],\n",
        "            \"next_agent\": \"AGENT_NAME or null if last step\"\n",
        "        }}\n",
        "    ],\n",
        "    \"combination_strategy\": \"How results will be joined/synthesized\",\n",
        "    \"expected_final_output\": \"Final deliverable specification\"\n",
        "}}\n",
        "\n",
        "**Example - EFFICIENT Single Agent (Revenue by industry):**\n",
        "\n",
        "Query: \"What industries have the highest customer lifetime value?\"\n",
        "{{\n",
        "    \"plan_summary\": \"RESEARCH_AGENT will use STRATEGIC_MARKET_ANALYST to analyze revenue by industry\",\n",
        "    \"total_steps\": 1,\n",
        "    \"steps\": [\n",
        "        {{\n",
        "            \"step_number\": 1,\n",
        "            \"agent\": \"RESEARCH_AGENT\",\n",
        "            \"tool\": \"STRATEGIC_MARKET_ANALYST\",\n",
        "            \"data_source\": \"STRATEGIC_RESEARCH_ANALYST semantic view\",\n",
        "            \"purpose\": \"Get revenue statistics aggregated by industry in a SINGLE query\",\n",
        "            \"consolidated_query\": \"Aggregate monthly_revenue and customer counts by industry, ordered by total revenue\",\n",
        "            \"expected_output\": \"industry, total_revenue, avg_revenue, customer_count\",\n",
        "            \"uses_data_from\": [],\n",
        "            \"next_agent\": null\n",
        "        }}\n",
        "    ],\n",
        "    \"combination_strategy\": \"Present ranked results directly\",\n",
        "    \"expected_final_output\": \"Ranked table of industries by revenue with customer counts\"\n",
        "}}\n",
        "\n",
        "**Example - EFFICIENT Multi-Agent (churn risk + complaints):**\n",
        "\n",
        "Query: \"Assess churn risk for customers complaining about API issues\"\n",
        "{{\n",
        "    \"plan_summary\": \"CONTENT_AGENT searches tickets for API complaints, then DATA_ANALYST_AGENT analyzes churn patterns\",\n",
        "    \"total_steps\": 2,\n",
        "    \"steps\": [\n",
        "        {{\n",
        "            \"step_number\": 1,\n",
        "            \"agent\": \"CONTENT_AGENT\",\n",
        "            \"tool\": \"CUSTOMER_FEEDBACK_SEARCH\",\n",
        "            \"data_source\": \"SUPPORT_TICKETS_SEARCH index\",\n",
        "            \"purpose\": \"Find API-related complaints and extract customer IDs\",\n",
        "            \"consolidated_query\": \"Semantic search: 'API error issue problem integration failure'\",\n",
        "            \"expected_output\": \"customer_ids and ticket summaries from matching tickets\",\n",
        "            \"uses_data_from\": [],\n",
        "            \"next_agent\": \"DATA_ANALYST_AGENT\"\n",
        "        }},\n",
        "        {{\n",
        "            \"step_number\": 2,\n",
        "            \"agent\": \"DATA_ANALYST_AGENT\",\n",
        "            \"tool\": \"BUSINESS_INTELLIGENCE_ANALYST\",\n",
        "            \"data_source\": \"CUSTOMER_BEHAVIOR_ANALYST semantic view\",\n",
        "            \"purpose\": \"Get behavior and churn metrics for identified customers in ONE query\",\n",
        "            \"consolidated_query\": \"Query customers, usage patterns, and churn events for the identified customer_ids\",\n",
        "            \"expected_output\": \"customer_id, status, monthly_revenue, usage metrics, churn indicators\",\n",
        "            \"uses_data_from\": [1],\n",
        "            \"next_agent\": null\n",
        "        }}\n",
        "    ],\n",
        "    \"combination_strategy\": \"Join ticket data with behavior metrics by customer_id\",\n",
        "    \"expected_final_output\": \"Risk-ranked list with complaint summary and churn indicators\"\n",
        "}}\n",
        "\n",
        "**Query:** {input}\n",
        "\n",
        "**RESPOND WITH ONLY THE JSON - Plan will be executed exactly as specified, no modifications.**\n",
        "\"\"\"\n",
        "\n",
        "planning_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", planning_prompt),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "print(\"‚úÖ Planning prompt updated - reflects actual agent tools and data sources\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Synthesis Prompt - Combines agent results into a clear, confident answer\n",
        "synthesis_prompt = \"\"\"\n",
        "You are an Executive AI Assistant synthesizing agent results into a clear answer.\n",
        "\n",
        "**Original Question**: {question}\n",
        "\n",
        "**Plan Summary**: {plan_summary}\n",
        "\n",
        "**Agent Results**:\n",
        "{agent_outputs}\n",
        "\n",
        "**Your Task**: Provide a clear, confident answer to the question using the data returned.\n",
        "\n",
        "**Synthesis Guidelines:**\n",
        "1. **Lead with the answer** - Start with the key finding that answers the question\n",
        "2. **Present what you learned** - Use the actual data returned by agents\n",
        "3. **Be confident** - Don't apologize for what wasn't analyzed\n",
        "4. **Be concise** - Executive summary style, not exhaustive reports\n",
        "5. **Add value** - Include actionable insights based on the data\n",
        "\n",
        "**DO NOT:**\n",
        "- List \"missing data\" or \"incomplete analysis\"\n",
        "- Mark steps as \"met/not met\"\n",
        "- Apologize for limitations\n",
        "- Add disclaimers about data gaps\n",
        "- Suggest the analysis is incomplete if you have enough to answer the question\n",
        "\n",
        "**Response Format:**\n",
        "\n",
        "## Summary\n",
        "[Direct answer to the question in 2-3 sentences with key metrics]\n",
        "\n",
        "## Key Findings\n",
        "[3-5 bullet points of important insights from the data]\n",
        "\n",
        "## Recommendations\n",
        "[2-3 actionable next steps based on findings]\n",
        "\n",
        "Keep the response focused and actionable. If the data answers the question, present it confidently.\n",
        "\"\"\"\n",
        "\n",
        "synthesis_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", synthesis_prompt),\n",
        "    (\"human\", \"Synthesize the agent results into a clear answer to the original question.\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Create Helper Functions\n",
        "\n",
        "We need several helper functions to work with the message state:\n",
        "\n",
        "1. **`get_latest_human_message`**: Extracts the user's query from the message list\n",
        "2. **`has_agent_response`**: Checks if any specialized agent has already responded\n",
        "3. **`get_agent_output`**: Retrieves the agent's response for synthesis\n",
        "\n",
        "These helpers make our node functions cleaner and handle various message formats (including LangGraph Studio's format).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All helper functions defined:\n",
            "   - get_latest_human_message()\n",
            "   - has_plan()\n",
            "   - get_current_step()\n",
            "   - is_plan_complete()\n",
            "   - get_all_agent_outputs()\n",
            "   - get_context_for_step()\n"
          ]
        }
      ],
      "source": [
        "def get_latest_human_message(messages: List[BaseMessage]) -> str:\n",
        "    \"\"\"Extract the latest human message content from the message list.\"\"\"\n",
        "    if not messages:\n",
        "        return \"\"\n",
        "    for msg in reversed(messages):\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            content = msg.content\n",
        "            if isinstance(content, list):\n",
        "                for item in content:\n",
        "                    if isinstance(item, dict) and item.get(\"type\") == \"text\":\n",
        "                        return item.get(\"text\", \"\")\n",
        "                    elif isinstance(item, str):\n",
        "                        return item\n",
        "            return str(content)\n",
        "        if isinstance(msg, dict):\n",
        "            if msg.get(\"type\") == \"human\" or msg.get(\"role\") == \"user\":\n",
        "                content = msg.get(\"content\", \"\")\n",
        "                if isinstance(content, list):\n",
        "                    for item in content:\n",
        "                        if isinstance(item, dict) and item.get(\"type\") == \"text\":\n",
        "                            return item.get(\"text\", \"\")\n",
        "                return str(content)\n",
        "    return \"\"\n",
        "\n",
        "# Agent names for identification\n",
        "AGENT_NAMES = [\"CONTENT_AGENT\", \"DATA_ANALYST_AGENT\", \"RESEARCH_AGENT\"]\n",
        "\n",
        "def has_plan(state) -> bool:\n",
        "    \"\"\"Check if an execution plan has been created.\"\"\"\n",
        "    return state.get(\"plan\") is not None and state.get(\"planning_complete\", False)\n",
        "\n",
        "def get_current_step(state):\n",
        "    \"\"\"Get the current step from the execution plan.\"\"\"\n",
        "    plan = state.get(\"plan\")\n",
        "    current_step_idx = state.get(\"current_step\", 0)\n",
        "    if plan and \"steps\" in plan:\n",
        "        steps = plan[\"steps\"]\n",
        "        if current_step_idx < len(steps):\n",
        "            return steps[current_step_idx]\n",
        "    return None\n",
        "\n",
        "def is_plan_complete(state) -> bool:\n",
        "    \"\"\"Check if all steps in the plan have been executed.\"\"\"\n",
        "    plan = state.get(\"plan\")\n",
        "    current_step_idx = state.get(\"current_step\", 0)\n",
        "    if plan and \"steps\" in plan:\n",
        "        return current_step_idx >= len(plan[\"steps\"])\n",
        "    return True\n",
        "\n",
        "def get_all_agent_outputs(state) -> Dict[str, str]:\n",
        "    \"\"\"Get all agent outputs from state (uses dedicated field for efficiency).\n",
        "    Falls back to message parsing if agent_outputs not populated.\"\"\"\n",
        "    # Prefer dedicated state field (more efficient)\n",
        "    if state.get(\"agent_outputs\"):\n",
        "        return state.get(\"agent_outputs\", {})\n",
        "    \n",
        "    # Fallback to message parsing\n",
        "    outputs = {}\n",
        "    messages = state.get(\"messages\", [])\n",
        "    for msg in messages:\n",
        "        if hasattr(msg, 'name') and msg.name in AGENT_NAMES:\n",
        "            content = msg.content if hasattr(msg, 'content') else str(msg)\n",
        "            outputs[msg.name] = content\n",
        "    return outputs\n",
        "\n",
        "def get_context_for_step(state, step: Dict) -> str:\n",
        "    \"\"\"Get context from previous agent output for the current step.\n",
        "    Uses agent_outputs state field for efficient access.\"\"\"\n",
        "    uses_data_from = step.get(\"uses_data_from\", [])\n",
        "    if not uses_data_from:\n",
        "        return \"\"\n",
        "    \n",
        "    agent_outputs = state.get(\"agent_outputs\", {})\n",
        "    plan = state.get(\"plan\", {})\n",
        "    steps = plan.get(\"steps\", [])\n",
        "    \n",
        "    context_parts = []\n",
        "    for step_num in uses_data_from:\n",
        "        # Find the agent that produced that step\n",
        "        for s in steps:\n",
        "            if s.get(\"step_number\") == step_num:\n",
        "                agent_name = s.get(\"agent\")\n",
        "                if agent_name in agent_outputs:\n",
        "                    output = agent_outputs[agent_name]\n",
        "                    # Truncate if too long\n",
        "                    if len(output) > 2000:\n",
        "                        output = output[:2000] + \"...\"\n",
        "                    context_parts.append(f\"From {agent_name}: {output}\")\n",
        "                break\n",
        "    \n",
        "    return \"\\n\".join(context_parts)\n",
        "\n",
        "print(\"‚úÖ All helper functions defined:\")\n",
        "print(\"   - get_latest_human_message()\")\n",
        "print(\"   - has_plan()\")\n",
        "print(\"   - get_current_step()\")\n",
        "print(\"   - is_plan_complete()\")\n",
        "print(\"   - get_all_agent_outputs()\")\n",
        "print(\"   - get_context_for_step()\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_agent_outputs_for_synthesis(outputs: Dict[str, str], plan: Dict) -> str:\n",
        "    \"\"\"Format agent outputs for synthesis - efficient and clean.\n",
        "    \n",
        "    Uses outputs from state.agent_outputs (not message parsing).\n",
        "    Includes consolidated query info from plan for context.\n",
        "    \"\"\"\n",
        "    formatted = []\n",
        "    for step in plan.get(\"steps\", []):\n",
        "        agent_name = step.get(\"agent\")\n",
        "        if agent_name in outputs:\n",
        "            output = outputs[agent_name]\n",
        "            # Truncate very long outputs to prevent token bloat\n",
        "            if len(output) > 5000:\n",
        "                output = output[:5000] + \"\\n... [truncated for brevity]\"\n",
        "            \n",
        "            formatted.append(f\"\"\"\n",
        "**{agent_name}** (Step {step.get('step_number')}/{plan.get('total_steps', len(plan.get('steps', [])))})\n",
        "Purpose: {step.get('purpose', 'N/A')}\n",
        "Query: {step.get('consolidated_query', 'N/A')[:100]}...\n",
        "\n",
        "Results:\n",
        "{output}\n",
        "\"\"\")\n",
        "    \n",
        "    if not formatted:\n",
        "        return \"No agent outputs available.\"\n",
        "    \n",
        "    return \"\\n\".join(formatted)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Create Node Functions\n",
        "\n",
        "Now we define the **node functions** - the actual work units of our graph. Each node:\n",
        "- Receives the current state\n",
        "- Performs some action (LLM call, agent invocation, etc.)\n",
        "- Returns state updates (new messages to add)\n",
        "\n",
        "### Node Types:\n",
        "1. **Supervisor Node**: Handles routing AND synthesis (dual-purpose)\n",
        "2. **Agent Nodes**: Invoke specialized Cortex agents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ supervisor_node() optimized - no re-planning, no LLM context extraction\n"
          ]
        }
      ],
      "source": [
        "# EFFICIENCY OPTIMIZATION: Removed LLM-based context extraction\n",
        "# Context is now passed directly via state.agent_outputs without extra LLM calls\n",
        "# This eliminates redundant supervisor re-entry and LLM invocations\n",
        "\n",
        "def supervisor_node(state: State) -> Command[Literal[\"CONTENT_AGENT\", \"DATA_ANALYST_AGENT\", \"RESEARCH_AGENT\", \"__end__\"]]:\n",
        "    \"\"\"\n",
        "    Supervisor node with EFFICIENCY OPTIMIZATIONS:\n",
        "    - ONE planning phase (no re-planning)\n",
        "    - Direct agent chaining (agents route to next agent, not back to supervisor)\n",
        "    - Context passed via state.agent_outputs (no LLM extraction)\n",
        "    - Only called for: 1) Planning, 2) Final synthesis\n",
        "    \"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "    plan = state.get(\"plan\")\n",
        "    \n",
        "    # ========================================\n",
        "    # MODE 1: PLANNING (only runs ONCE)\n",
        "    # ========================================\n",
        "    if not has_plan(state):\n",
        "        latest_message = get_latest_human_message(messages)\n",
        "        \n",
        "        if not latest_message:\n",
        "            return Command(\n",
        "                update={\n",
        "                    \"plan\": {\"steps\": [], \"plan_summary\": \"No query\"},\n",
        "                    \"planning_complete\": True\n",
        "                },\n",
        "                goto=\"__end__\"\n",
        "            )\n",
        "        \n",
        "        try:\n",
        "            planning_chain = planning_prompt_template | supervisor_model\n",
        "            response = planning_chain.invoke({\"input\": latest_message})\n",
        "            content = response.content if hasattr(response, 'content') else str(response)\n",
        "            \n",
        "            # Parse JSON plan\n",
        "            if \"{\" in content and \"}\" in content:\n",
        "                start = content.find(\"{\")\n",
        "                end = content.rfind(\"}\") + 1\n",
        "                plan = json.loads(content[start:end])\n",
        "            else:\n",
        "                raise ValueError(\"No valid JSON found\")\n",
        "            \n",
        "            # Display clean plan summary\n",
        "            print(f\"\\n{'‚îÅ'*60}\")\n",
        "            print(\"üìã EXECUTION PLAN (IMMUTABLE)\")\n",
        "            print(f\"{'‚îÅ'*60}\")\n",
        "            print(f\"\\n{plan.get('plan_summary', 'N/A')}\")\n",
        "            print(f\"\\nüìç Steps ({plan.get('total_steps', len(plan.get('steps', [])))} total):\")\n",
        "            for step in plan.get(\"steps\", []):\n",
        "                next_agent = step.get('next_agent', 'SYNTHESIS')\n",
        "                print(f\"   {step.get('step_number')}. {step.get('agent')} ‚Üí {next_agent}\")\n",
        "                print(f\"      Purpose: {step.get('purpose', 'N/A')[:50]}...\")\n",
        "            print(f\"{'‚îÅ'*60}\\n\")\n",
        "            \n",
        "            # Get first agent - plan will NOT be modified after this\n",
        "            first_step = plan.get(\"steps\", [{}])[0] if plan.get(\"steps\") else {}\n",
        "            first_agent = first_step.get(\"agent\", \"CONTENT_AGENT\")\n",
        "            \n",
        "            return Command(\n",
        "                update={\n",
        "                    \"plan\": plan,\n",
        "                    \"current_step\": 0,\n",
        "                    \"planning_complete\": True,  # Lock the plan\n",
        "                    \"agent_outputs\": {},\n",
        "                    \"execution_errors\": []\n",
        "                },\n",
        "                goto=first_agent\n",
        "            )\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Planning error: {e}\")\n",
        "            fallback_plan = {\n",
        "                \"plan_summary\": \"Direct query routing (planning failed)\",\n",
        "                \"total_steps\": 1,\n",
        "                \"steps\": [{\"step_number\": 1, \"agent\": \"CONTENT_AGENT\", \"purpose\": \"Handle query\", \"next_agent\": None}],\n",
        "                \"combination_strategy\": \"Present agent response directly\"\n",
        "            }\n",
        "            return Command(\n",
        "                update={\n",
        "                    \"plan\": fallback_plan,\n",
        "                    \"current_step\": 0,\n",
        "                    \"planning_complete\": True,\n",
        "                    \"agent_outputs\": {},\n",
        "                    \"execution_errors\": []\n",
        "                },\n",
        "                goto=\"CONTENT_AGENT\"\n",
        "            )\n",
        "    \n",
        "    # ========================================\n",
        "    # MODE 2: ROUTING (route to next agent based on plan)\n",
        "    # ========================================\n",
        "    # Check if there are more steps to execute\n",
        "    if not is_plan_complete(state):\n",
        "        current_step = get_current_step(state)\n",
        "        if current_step:\n",
        "            next_agent = current_step.get(\"agent\")\n",
        "            if next_agent and next_agent in AGENT_NAMES:\n",
        "                print(f\"   ‚Üí Routing to {next_agent}\")\n",
        "                return Command(goto=next_agent)\n",
        "    \n",
        "    # ========================================\n",
        "    # MODE 3: SYNTHESIS (when plan is complete)\n",
        "    # ========================================\n",
        "    original_question = get_latest_human_message(messages)\n",
        "    agent_outputs = get_all_agent_outputs(state)\n",
        "    execution_errors = state.get(\"execution_errors\", [])\n",
        "    \n",
        "    print(f\"üìä Synthesizing results from {len(agent_outputs)} agent(s)...\")\n",
        "    if execution_errors:\n",
        "        print(f\"   ‚ö†Ô∏è {len(execution_errors)} error(s) occurred during execution\")\n",
        "    \n",
        "    try:\n",
        "        formatted_outputs = format_agent_outputs_for_synthesis(agent_outputs, plan)\n",
        "        \n",
        "        # Add error summary if any\n",
        "        if execution_errors:\n",
        "            formatted_outputs += f\"\\n\\n**Execution Notes:**\\n- {len(execution_errors)} non-critical error(s) occurred\\n\"\n",
        "        \n",
        "        synthesis_chain = synthesis_prompt_template | supervisor_model\n",
        "        response = synthesis_chain.invoke({\n",
        "            \"question\": original_question,\n",
        "            \"plan_summary\": plan.get(\"plan_summary\", \"\"),\n",
        "            \"step_dependencies\": \"Data flows according to plan\",\n",
        "            \"combination_strategy\": plan.get(\"combination_strategy\", \"\"),\n",
        "            \"expected_final_output\": plan.get(\"expected_final_output\", \"Comprehensive analysis\"),\n",
        "            \"agent_outputs\": formatted_outputs\n",
        "        })\n",
        "        \n",
        "        content = response.content if hasattr(response, 'content') else str(response)\n",
        "        print(f\"‚úÖ Analysis complete\\n\")\n",
        "        \n",
        "        return Command(\n",
        "            update={\"messages\": [AIMessage(content=content, name=\"supervisor\")]},\n",
        "            goto=\"__end__\"\n",
        "        )\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Synthesis error: {e}\")\n",
        "        raw_outputs = \"\\n\\n\".join([f\"**{k}**:\\n{v[:2000]}\" for k, v in agent_outputs.items()])\n",
        "        return Command(\n",
        "            update={\"messages\": [AIMessage(content=f\"Analysis completed:\\n\\n{raw_outputs}\", name=\"supervisor\")]},\n",
        "            goto=\"__end__\"\n",
        "        )\n",
        "\n",
        "print(\"‚úÖ supervisor_node() optimized - no re-planning, no LLM context extraction\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ content_agent_node() defined\n"
          ]
        }
      ],
      "source": [
        "def build_query_with_context(original_query: str, state: State) -> str:\n",
        "    \"\"\"Build query with context from previous agent outputs (no LLM extraction needed).\"\"\"\n",
        "    current_step = get_current_step(state)\n",
        "    if not current_step:\n",
        "        return original_query\n",
        "    \n",
        "    # Get context directly from state\n",
        "    context = get_context_for_step(state, current_step)\n",
        "    if context:\n",
        "        return f\"{original_query}\\n\\nContext from previous analysis:\\n{context}\"\n",
        "    return original_query\n",
        "\n",
        "\n",
        "def content_agent_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    \"\"\"Content Agent node - handles customer feedback and sentiment analysis.\n",
        "    \n",
        "    Always routes back to supervisor for clean hub-and-spoke architecture.\n",
        "    Supervisor handles routing to next agent based on plan.\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    query = get_latest_human_message(messages)\n",
        "    current_step_idx = state.get(\"current_step\", 0)\n",
        "    agent_outputs = state.get(\"agent_outputs\", {}).copy()\n",
        "    execution_errors = state.get(\"execution_errors\", []).copy()\n",
        "    \n",
        "    # Build query with context from previous steps\n",
        "    enhanced_query = build_query_with_context(query, state)\n",
        "    \n",
        "    print(f\"üîç CONTENT_AGENT analyzing...\")\n",
        "    \n",
        "    try:\n",
        "        result = content_agent.invoke(enhanced_query)\n",
        "        response_content = result.get(\"output\", \"\")\n",
        "        print(f\"   ‚úì Complete ({len(response_content)} chars)\")\n",
        "        \n",
        "        # Store in dedicated state field for efficient access\n",
        "        agent_outputs[\"CONTENT_AGENT\"] = response_content\n",
        "        \n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=response_content, name=\"CONTENT_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1,\n",
        "                \"agent_outputs\": agent_outputs\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"CONTENT_AGENT error: {str(e)}\"\n",
        "        print(f\"   ‚úó {error_msg}\")\n",
        "        execution_errors.append(error_msg)\n",
        "        \n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=f\"Error occurred: {str(e)}\", name=\"CONTENT_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1,\n",
        "                \"agent_outputs\": agent_outputs,\n",
        "                \"execution_errors\": execution_errors\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "\n",
        "print(\"‚úÖ content_agent_node() defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ data_analyst_agent_node() defined\n"
          ]
        }
      ],
      "source": [
        "def parse_agent_stream_response(chunks: List[str]) -> tuple[str, List[str]]:\n",
        "    \"\"\"Parse streaming response from Cortex Agent.\n",
        "    \n",
        "    EFFICIENCY OPTIMIZATION: Aggregates errors instead of appending each one.\n",
        "    Returns (content, errors) tuple.\n",
        "    \"\"\"\n",
        "    response_parts = []\n",
        "    errors = []\n",
        "    \n",
        "    for chunk in chunks:\n",
        "        try:\n",
        "            chunk_data = json.loads(chunk)\n",
        "            if isinstance(chunk_data, dict):\n",
        "                if chunk_data.get(\"type\") == \"text\":\n",
        "                    response_parts.append(chunk_data.get(\"text\", \"\"))\n",
        "                elif \"content\" in chunk_data:\n",
        "                    response_parts.append(str(chunk_data.get(\"content\", \"\")))\n",
        "                elif \"message\" in chunk_data:\n",
        "                    # Collect error but don't append to output (avoids cascading)\n",
        "                    errors.append(chunk_data.get(\"message\", \"Unknown error\"))\n",
        "            else:\n",
        "                response_parts.append(str(chunk_data))\n",
        "        except (json.JSONDecodeError, TypeError):\n",
        "            # Only append non-JSON chunks that look like actual content\n",
        "            if chunk and not chunk.startswith(\"{\"):\n",
        "                response_parts.append(chunk)\n",
        "    \n",
        "    return \"\".join(response_parts), errors\n",
        "\n",
        "\n",
        "def data_analyst_agent_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    \"\"\"Data Analyst Agent node - handles metrics and analytics queries.\n",
        "    \n",
        "    Always routes back to supervisor for clean hub-and-spoke architecture.\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    original_query = get_latest_human_message(messages)\n",
        "    current_step_idx = state.get(\"current_step\", 0)\n",
        "    agent_outputs = state.get(\"agent_outputs\", {}).copy()\n",
        "    execution_errors = state.get(\"execution_errors\", []).copy()\n",
        "    \n",
        "    # Build query with context from previous steps\n",
        "    query = build_query_with_context(original_query, state)\n",
        "    \n",
        "    print(f\"üìä DATA_ANALYST_AGENT analyzing...\")\n",
        "    \n",
        "    try:\n",
        "        chunks = []\n",
        "        for chunk in data_analyst_agent.stream(query):\n",
        "            chunks.append(str(chunk))\n",
        "        \n",
        "        # Parse response with aggregated error handling\n",
        "        response_content, stream_errors = parse_agent_stream_response(chunks)\n",
        "        \n",
        "        # Report aggregated errors once (not per-chunk)\n",
        "        if stream_errors:\n",
        "            unique_errors = list(set(stream_errors))  # Deduplicate\n",
        "            if len(unique_errors) > 0:\n",
        "                print(f\"   ‚ö†Ô∏è {len(unique_errors)} unique error(s) during streaming\")\n",
        "                execution_errors.extend([f\"DATA_ANALYST streaming: {e}\" for e in unique_errors[:3]])  # Cap at 3\n",
        "        \n",
        "        print(f\"   ‚úì Complete ({len(response_content)} chars)\")\n",
        "        \n",
        "        # Store in dedicated state field\n",
        "        agent_outputs[\"DATA_ANALYST_AGENT\"] = response_content\n",
        "        \n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=response_content, name=\"DATA_ANALYST_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1,\n",
        "                \"agent_outputs\": agent_outputs,\n",
        "                \"execution_errors\": execution_errors\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"DATA_ANALYST_AGENT error: {str(e)}\"\n",
        "        print(f\"   ‚úó {error_msg}\")\n",
        "        execution_errors.append(error_msg)\n",
        "        \n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=f\"Error occurred: {str(e)}\", name=\"DATA_ANALYST_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1,\n",
        "                \"agent_outputs\": agent_outputs,\n",
        "                \"execution_errors\": execution_errors\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "\n",
        "print(\"‚úÖ data_analyst_agent_node() defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ research_agent_node() defined\n"
          ]
        }
      ],
      "source": [
        "def research_agent_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    \"\"\"Research Agent node - handles market and strategic analysis.\n",
        "    \n",
        "    Always routes back to supervisor for clean hub-and-spoke architecture.\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    original_query = get_latest_human_message(messages)\n",
        "    current_step_idx = state.get(\"current_step\", 0)\n",
        "    agent_outputs = state.get(\"agent_outputs\", {}).copy()\n",
        "    execution_errors = state.get(\"execution_errors\", []).copy()\n",
        "    \n",
        "    # Build query with context from previous steps\n",
        "    query = build_query_with_context(original_query, state)\n",
        "    \n",
        "    print(f\"üî¨ RESEARCH_AGENT analyzing...\")\n",
        "    \n",
        "    try:\n",
        "        chunks = []\n",
        "        for chunk in research_agent.stream(query):\n",
        "            chunks.append(str(chunk))\n",
        "        \n",
        "        # Parse response with aggregated error handling\n",
        "        response_content, stream_errors = parse_agent_stream_response(chunks)\n",
        "        \n",
        "        # Report aggregated errors once (not per-chunk)\n",
        "        if stream_errors:\n",
        "            unique_errors = list(set(stream_errors))\n",
        "            if len(unique_errors) > 0:\n",
        "                print(f\"   ‚ö†Ô∏è {len(unique_errors)} unique error(s) during streaming\")\n",
        "                execution_errors.extend([f\"RESEARCH streaming: {e}\" for e in unique_errors[:3]])\n",
        "        \n",
        "        print(f\"   ‚úì Complete ({len(response_content)} chars)\")\n",
        "        \n",
        "        # Store in dedicated state field\n",
        "        agent_outputs[\"RESEARCH_AGENT\"] = response_content\n",
        "        \n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=response_content, name=\"RESEARCH_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1,\n",
        "                \"agent_outputs\": agent_outputs,\n",
        "                \"execution_errors\": execution_errors\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"RESEARCH_AGENT error: {str(e)}\"\n",
        "        print(f\"   ‚úó {error_msg}\")\n",
        "        execution_errors.append(error_msg)\n",
        "        \n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [AIMessage(content=f\"Error occurred: {str(e)}\", name=\"RESEARCH_AGENT\")],\n",
        "                \"current_step\": current_step_idx + 1,\n",
        "                \"agent_outputs\": agent_outputs,\n",
        "                \"execution_errors\": execution_errors\n",
        "            },\n",
        "            goto=\"supervisor\"\n",
        "        )\n",
        "\n",
        "print(\"‚úÖ research_agent_node() defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Create the Routing Function\n",
        "\n",
        "The **routing function** is used by LangGraph's conditional edges. It:\n",
        "1. Reads the supervisor's routing decision (JSON)\n",
        "2. Parses the `next_agent` field\n",
        "3. Returns the name of the next node to execute\n",
        "\n",
        "This enables dynamic routing based on the supervisor's analysis of each query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Routing configured with edges\n"
          ]
        }
      ],
      "source": [
        "# Routing logic is now defined with edges in the graph setup cell\n",
        "print(\"‚úÖ Routing configured with edges\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Build the Workflow Graph\n",
        "\n",
        "Now we assemble all the pieces into a **StateGraph**. The graph defines:\n",
        "\n",
        "1. **Nodes**: The processing units (supervisor + 3 agents)\n",
        "2. **Edges**: The connections between nodes\n",
        "3. **Conditional Edges**: Dynamic routing based on state\n",
        "\n",
        "### Graph Structure:\n",
        "```\n",
        "START \n",
        "  ‚Üì\n",
        "supervisor (routing)\n",
        "  ‚Üì (conditional)\n",
        "  ‚îú‚îÄ‚îÄ CONTENT_AGENT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "  ‚îú‚îÄ‚îÄ DATA_ANALYST_AGENT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ supervisor (synthesis)\n",
        "  ‚îî‚îÄ‚îÄ RESEARCH_AGENT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚Üì\n",
        "                                       END\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ StateGraph created\n",
            "   Added node: supervisor\n",
            "   Added node: CONTENT_AGENT\n",
            "   Added node: DATA_ANALYST_AGENT\n",
            "   Added node: RESEARCH_AGENT\n"
          ]
        }
      ],
      "source": [
        "# Create the StateGraph with our State type\n",
        "workflow = StateGraph(State)\n",
        "print(\"‚úÖ StateGraph created\")\n",
        "\n",
        "# Add the supervisor node\n",
        "workflow.add_node(\"supervisor\", supervisor_node)\n",
        "print(\"   Added node: supervisor\")\n",
        "\n",
        "# Add the agent nodes\n",
        "workflow.add_node(\"CONTENT_AGENT\", content_agent_node)\n",
        "print(\"   Added node: CONTENT_AGENT\")\n",
        "\n",
        "workflow.add_node(\"DATA_ANALYST_AGENT\", data_analyst_agent_node)\n",
        "print(\"   Added node: DATA_ANALYST_AGENT\")\n",
        "\n",
        "workflow.add_node(\"RESEARCH_AGENT\", research_agent_node)\n",
        "print(\"   Added node: RESEARCH_AGENT\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Graph edges configured\n",
            "   Entry: START ‚Üí supervisor\n",
            "   Routing: Handled by Command.goto in each node\n"
          ]
        }
      ],
      "source": [
        "# Define the graph edges\n",
        "# With Command routing, nodes specify their own destinations via goto\n",
        "\n",
        "# Only need the entry point - Command handles all other routing\n",
        "workflow.add_edge(START, \"supervisor\")\n",
        "\n",
        "print(\"‚úÖ Graph edges configured\")\n",
        "print(\"   Entry: START ‚Üí supervisor\")\n",
        "print(\"   Routing: Handled by Command.goto in each node\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Compile the Workflow\n",
        "\n",
        "Compiling the graph creates an executable application. The compiled graph:\n",
        "- Validates the graph structure\n",
        "- Creates an optimized execution plan\n",
        "- Returns a runnable object that can be invoked with input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Workflow compiled successfully!\n",
            "\n",
            "üìä Workflow Summary (HUB-AND-SPOKE ARCHITECTURE):\n",
            "   ‚Ä¢ 1 Supervisor node (central coordinator)\n",
            "   ‚Ä¢ 3 Specialized agent nodes (spokes)\n",
            "   ‚Ä¢ Clean flat graph: all agents route through supervisor\n",
            "   ‚Ä¢ Flow: START ‚Üí supervisor ‚Üí Agent ‚Üí supervisor ‚Üí Agent ‚Üí supervisor ‚Üí END\n",
            "\n",
            "üöÄ Efficiency Features:\n",
            "   ‚Ä¢ Immutable plan - created once, never modified during execution\n",
            "   ‚Ä¢ No LLM calls for routing - supervisor uses simple plan lookup\n",
            "   ‚Ä¢ Consolidated queries - single SQL aggregation instead of multiple calls\n",
            "   ‚Ä¢ Aggregated error handling - errors collected, not cascaded\n",
            "   ‚Ä¢ State-based context passing - no LLM calls for context extraction\n"
          ]
        }
      ],
      "source": [
        "# Compile the workflow into an executable application\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"‚úÖ Workflow compiled successfully!\")\n",
        "print(\"\\nüìä Workflow Summary (HUB-AND-SPOKE ARCHITECTURE):\")\n",
        "print(\"   ‚Ä¢ 1 Supervisor node (central coordinator)\")\n",
        "print(\"   ‚Ä¢ 3 Specialized agent nodes (spokes)\")\n",
        "print(\"   ‚Ä¢ Clean flat graph: all agents route through supervisor\")\n",
        "print(\"   ‚Ä¢ Flow: START ‚Üí supervisor ‚Üí Agent ‚Üí supervisor ‚Üí Agent ‚Üí supervisor ‚Üí END\")\n",
        "print(\"\\nüöÄ Efficiency Features:\")\n",
        "print(\"   ‚Ä¢ Immutable plan - created once, never modified during execution\")\n",
        "print(\"   ‚Ä¢ No LLM calls for routing - supervisor uses simple plan lookup\")\n",
        "print(\"   ‚Ä¢ Consolidated queries - single SQL aggregation instead of multiple calls\")\n",
        "print(\"   ‚Ä¢ Aggregated error handling - errors collected, not cascaded\")\n",
        "print(\"   ‚Ä¢ State-based context passing - no LLM calls for context extraction\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Visualize the Graph (Optional)\n",
        "\n",
        "LangGraph can generate a visual representation of the workflow. This requires the `pygraphviz` or `grandalf` library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Graph visualization generated\n"
          ]
        }
      ],
      "source": [
        "# Try to visualize the graph (requires graphviz)\n",
        "try:\n",
        "    from IPython.display import Image, display\n",
        "    \n",
        "    # Generate the graph visualization\n",
        "    graph_image = app.get_graph().draw_mermaid_png()\n",
        "    display(Image(graph_image))\n",
        "    print(\"‚úÖ Graph visualization generated\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ÑπÔ∏è Graph visualization not available: {e}\")\n",
        "    print(\"   Install pygraphviz or grandalf for visualization support\")\n",
        "    print(\"\\n   Graph structure:\")\n",
        "    print(\"   START ‚Üí supervisor ‚Üí [CONTENT_AGENT | DATA_ANALYST_AGENT | RESEARCH_AGENT] ‚Üí supervisor ‚Üí END\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Test the Workflow\n",
        "\n",
        "Now let's test the workflow with some sample queries! Each query type should be routed to a different agent:\n",
        "\n",
        "| Query Type | Expected Agent |\n",
        "|------------|----------------|\n",
        "| Customer feedback, sentiment, complaints | CONTENT_AGENT |\n",
        "| Metrics, behavior, churn, analytics | DATA_ANALYST_AGENT |\n",
        "| Market research, competition, strategy | RESEARCH_AGENT |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/langgraph_snowflake/lib/python3.11/site-packages/munch/__init__.py:24: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ TruLens dependencies imported successfully!\n"
          ]
        }
      ],
      "source": [
        "from trulens.apps.langgraph import TruGraph\n",
        "from trulens.connectors.snowflake import SnowflakeConnector\n",
        "from trulens.providers.cortex import Cortex\n",
        "from trulens.core.feedback.custom_metric import MetricConfig\n",
        "from trulens.core.feedback.selector import Selector\n",
        "from trulens.core.run import Run, RunConfig\n",
        "from functools import partial\n",
        "import uuid\n",
        "\n",
        "print(\"‚úÖ TruLens dependencies imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running the TruLens dashboard requires providing a `password` to the `SnowflakeConnector`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Snowflake connector created for TruLens\n",
            "‚úÖ Cortex evaluation provider initialized\n",
            "   Model: claude-opus-4-5\n"
          ]
        }
      ],
      "source": [
        "# Connect TruLens to Snowflake for observability\n",
        "# This uses the same session we created earlier\n",
        "\n",
        "sf_connector = SnowflakeConnector(snowpark_session=session)\n",
        "print(\"‚úÖ Snowflake connector created for TruLens\")\n",
        "\n",
        "# Initialize the Cortex provider for client-side evaluations\n",
        "# This provider will use Snowflake Cortex LLMs to compute custom metrics\n",
        "trace_eval_provider = Cortex(\n",
        "    model_engine=\"claude-opus-4-5\",\n",
        "    snowpark_session=session\n",
        ")\n",
        "print(\"‚úÖ Cortex evaluation provider initialized\")\n",
        "print(f\"   Model: {trace_eval_provider.model_engine}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Plan Quality metric configured\n",
            "‚úÖ Plan Adherence metric configured\n",
            "‚úÖ Execution Efficiency metric configured\n",
            "‚úÖ Logical Consistency metric configured\n"
          ]
        }
      ],
      "source": [
        "# Plan Quality - Evaluates how well the supervisor creates execution plans\n",
        "f_plan_quality = MetricConfig(\n",
        "    metric_implementation=partial(\n",
        "        trace_eval_provider.plan_quality_with_cot_reasons,\n",
        "        # enable_trace_compression=False\n",
        "    ),\n",
        "    metric_name=\"Plan Quality\",\n",
        "    selectors={\n",
        "        \"trace\": Selector(trace_level=True),\n",
        "    },\n",
        ")\n",
        "print(\"‚úÖ Plan Quality metric configured\")\n",
        "\n",
        "# Plan Adherence - Checks if the agent follows the execution plan\n",
        "f_plan_adherence = MetricConfig(\n",
        "    metric_implementation=partial(\n",
        "        trace_eval_provider.plan_adherence_with_cot_reasons,\n",
        "        # enable_trace_compression=False\n",
        "    ),\n",
        "    metric_name=\"Plan Adherence\",\n",
        "    selectors={\n",
        "        \"trace\": Selector(trace_level=True),\n",
        "    },\n",
        ")\n",
        "print(\"‚úÖ Plan Adherence metric configured\")\n",
        "\n",
        "# Execution Efficiency - Measures workflow efficiency\n",
        "f_execution_efficiency = MetricConfig(\n",
        "    metric_implementation=partial(\n",
        "        trace_eval_provider.execution_efficiency_with_cot_reasons,\n",
        "        # enable_trace_compression=False\n",
        "    ),\n",
        "    metric_name=\"Execution Efficiency\",\n",
        "    selectors={\n",
        "        \"trace\": Selector(trace_level=True),\n",
        "    },\n",
        ")\n",
        "print(\"‚úÖ Execution Efficiency metric configured\")\n",
        "\n",
        "# Logical Consistency - Verifies consistency across agent responses\n",
        "f_logical_consistency = MetricConfig(\n",
        "    metric_implementation=partial(\n",
        "        trace_eval_provider.logical_consistency_with_cot_reasons,\n",
        "        # enable_trace_compression=False\n",
        "    ),\n",
        "    metric_name=\"Logical Consistency\",\n",
        "    selectors={\n",
        "        \"trace\": Selector(trace_level=True),\n",
        "    },\n",
        ")\n",
        "print(\"‚úÖ Logical Consistency metric configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 14: Instrument with TruLens and Run Evaluation\n",
        "\n",
        "Now we wrap the LangGraph application directly with `TruGraph` and run evaluation with full LangGraph input states.\n",
        "\n",
        "The evaluation dataset contains actual LangGraph state dicts (with `messages` key) that are passed directly to `graph.invoke()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ experimental Feature.OTEL_TRACING enabled.\n",
            "üîí experimental Feature.OTEL_TRACING is enabled and cannot be changed.\n",
            "instrumenting <class 'langgraph.graph.state.StateGraph'> for base <class 'langgraph.graph.state.StateGraph'>\n",
            "instrumenting <class 'langgraph.graph.state.CompiledStateGraph'> for base <class 'langgraph.graph.state.CompiledStateGraph'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "\tinstrumenting astream_events\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "\tinstrumenting astream_events\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "\tinstrumenting stream_mode\n",
            "instrumenting <class 'langgraph.graph.state.CompiledStateGraph'> for base <class 'langgraph.pregel.main.Pregel'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "\tinstrumenting astream_events\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "\tinstrumenting astream_events\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "\tinstrumenting stream_mode\n",
            "‚úÖ TruGraph instrumented app created\n",
            "   App Name: Customer Intelligence Multi-Agent\n",
            "   App Version: Vc9a9e23b\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluator thread encountered an error: 'str' object has no attribute 'get'\n"
          ]
        }
      ],
      "source": [
        "# Generate unique app name and version\n",
        "APP_NAME = f\"Customer Intelligence Multi-Agent\"\n",
        "APP_VERSION = f\"V{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "# Directly wrap the LangGraph graph with TruGraph\n",
        "tru_app = TruGraph(\n",
        "    app,  # The compiled StateGraph from Step 11\n",
        "    app_name=APP_NAME,\n",
        "    app_version=APP_VERSION,\n",
        "    main_method=app.invoke,  # Use graph's invoke method directly\n",
        "    connector=sf_connector,\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ TruGraph instrumented app created\")\n",
        "print(f\"   App Name: {APP_NAME}\")\n",
        "print(f\"   App Version: {APP_VERSION}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define all metrics to compute (server-side + client-side)\n",
        "metrics_to_compute = [\n",
        "    # Server-side metrics\n",
        "    \"answer_relevance\",\n",
        "    # Client-side metrics\n",
        "    f_plan_quality,\n",
        "    f_plan_adherence,\n",
        "    f_execution_efficiency,\n",
        "    f_logical_consistency,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "Congratulations! üéâ You've successfully built an **efficiency-optimized multi-agent supervisor workflow** using LangGraph and Snowflake Cortex. Here's what we accomplished:\n",
        "\n",
        "### Key Components Built:\n",
        "\n",
        "1. **Extended State Management**: Custom state with `messages`, `plan`, `agent_outputs`, and `execution_errors`\n",
        "2. **Supervisor Model**: `ChatSnowflake` for intelligent planning and synthesis (2 modes only)\n",
        "3. **Specialized Agents**: Three `SnowflakeCortexAgent` instances with direct chaining\n",
        "4. **Efficient Prompt Engineering**: Planning prompt emphasizing consolidated queries and clear tool separation\n",
        "5. **Optimized Node Functions**: Agents route directly to each other without supervisor re-entry\n",
        "6. **Graph Structure**: Linear execution with plan-based agent chaining\n",
        "\n",
        "### Efficiency-Optimized Architecture:\n",
        "\n",
        "```\n",
        "User Query ‚Üí Supervisor (Plan ONCE) ‚Üí Agent1 ‚Üí Agent2... ‚Üí Supervisor (Synthesize ONCE) ‚Üí Executive Summary\n",
        "```\n",
        "\n",
        "### Efficiency Improvements Implemented:\n",
        "\n",
        "| Issue | Solution |\n",
        "|-------|----------|\n",
        "| **Repeated planning/re-planning** | Immutable plan - created once, locked with `planning_complete` flag |\n",
        "| **Cascading error chains** | Aggregated error handling - errors collected and deduplicated, not appended per-chunk |\n",
        "| **Supervisor bottleneck** | Direct agent chaining via `next_agent` field in plan steps |\n",
        "| **Redundant tool invocations** | Planning prompt emphasizes consolidated SQL queries (one aggregation vs multiple) |\n",
        "| **Duplicated invocations** | Supervisor only called twice (plan + synthesize), not between each agent |\n",
        "| **Overlapping tooling** | Clear tool separation - each agent has ONE tool with distinct data sources |\n",
        "\n",
        "### Planning Features:\n",
        "\n",
        "The supervisor creates a **single, immutable execution plan** that includes:\n",
        "- **`next_agent` Field**: Enables direct agent-to-agent routing\n",
        "- **`consolidated_query`**: Encourages single queries instead of multiple separate calls\n",
        "- **Clear Tool Boundaries**: CONTENT_AGENT (cortex_search), DATA_ANALYST_AGENT (cortex_analyst on metrics), RESEARCH_AGENT (cortex_analyst on analytics)\n",
        "- **`total_steps`**: Explicit step count for progress tracking\n",
        "\n",
        "### Error Handling Strategy:\n",
        "\n",
        "- Errors collected in `state.execution_errors` array (not cascaded in output)\n",
        "- Unique errors deduplicated before storage\n",
        "- Graceful degradation - agents continue to next step even on partial errors\n",
        "- Summary synthesis includes error count without verbose per-chunk messages\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "- **Add more agents**: Extend the workflow with additional specialized agents\n",
        "- **Implement memory**: Add conversation persistence with LangGraph checkpointers\n",
        "- **Add human-in-the-loop**: Include plan approval steps for critical decisions\n",
        "- **Deploy to production**: Use LangGraph Cloud or LangGraph Studio for deployment\n",
        "\n",
        "### Resources:\n",
        "\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
        "- [Snowflake Cortex Documentation](https://docs.snowflake.com/en/user-guide/snowflake-cortex)\n",
        "- [LangChain Snowflake Integration](https://python.langchain.com/docs/integrations/providers/snowflake)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define evaluation inputs as full LangGraph state dicts\n",
        "# This passes the actual state that LangGraph expects directly to graph.invoke()\n",
        "evaluation_inputs = [\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"Assess the churn risk for customers complaining about API issues.\")],\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"What industries have the highest customer lifetime value and represent our best strategic expansion opportunities?\")],\n",
        "    },\n",
        "]\n",
        "\n",
        "# Create DataFrame with the state dicts\n",
        "queries_df = pd.DataFrame({\"input_state\": evaluation_inputs})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Run configuration created\n",
            "   Run Name: customer_intel_eval_bc1406c5\n",
            "   Dataset: customer_intelligence_queries\n",
            "   Source: DataFrame with 2 input states\n",
            "\n",
            "‚úÖ Run added to TruGraph app\n"
          ]
        }
      ],
      "source": [
        "# Create unique run name\n",
        "run_name = f\"customer_intel_eval_{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "# Configure the evaluation run\n",
        "# The dataset_spec maps to the column containing full LangGraph state dicts\n",
        "run_config = RunConfig(\n",
        "    run_name=run_name,\n",
        "    dataset_name=\"customer_intelligence_queries\",\n",
        "    source_type=\"DATAFRAME\",\n",
        "    dataset_spec={\"RECORD_ROOT.INPUT\": \"input_state\"},  # Maps to state dict column\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Run configuration created\")\n",
        "print(f\"   Run Name: {run_name}\")\n",
        "print(f\"   Dataset: customer_intelligence_queries\")\n",
        "print(f\"   Source: DataFrame with {len(queries_df)} input states\")\n",
        "\n",
        "# Add the run to the instrumented app\n",
        "run: Run = tru_app.add_run(run_config=run_config)\n",
        "print(f\"\\n‚úÖ Run added to TruGraph app\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üöÄ Starting evaluation run...\n",
            "   Processing 2 queries through the multi-agent workflow\n",
            "\n",
            "\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
            "üìã EXECUTION PLAN (IMMUTABLE)\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
            "\n",
            "CONTENT_AGENT will search for API-related complaints, then DATA_ANALYST_AGENT will analyze churn patterns for those customers\n",
            "\n",
            "üìç Steps (2 total):\n",
            "   1. CONTENT_AGENT ‚Üí DATA_ANALYST_AGENT\n",
            "      Purpose: Find API-related complaints and extract customer I...\n",
            "   2. DATA_ANALYST_AGENT ‚Üí None\n",
            "      Purpose: Get comprehensive churn risk metrics for identifie...\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
            "\n",
            "üîç CONTENT_AGENT analyzing...\n",
            "   ‚úì Complete (11798 chars)\n",
            "   ‚Üí Routing to DATA_ANALYST_AGENT\n",
            "üìä DATA_ANALYST_AGENT analyzing...\n",
            "   ‚ö†Ô∏è 18 unique error(s) during streaming\n",
            "   ‚úì Complete (27711 chars)\n",
            "üìä Synthesizing results from 2 agent(s)...\n",
            "   ‚ö†Ô∏è 3 error(s) occurred during execution\n",
            "‚úÖ Analysis complete\n",
            "\n",
            "\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
            "üìã EXECUTION PLAN (IMMUTABLE)\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
            "\n",
            "RESEARCH_AGENT will use STRATEGIC_MARKET_ANALYST to analyze CLV by industry and CUSTOMER_SEGMENT_INTELLIGENCE to assess strategic expansion opportunities\n",
            "\n",
            "üìç Steps (2 total):\n",
            "   1. RESEARCH_AGENT ‚Üí RESEARCH_AGENT\n",
            "      Purpose: Calculate comprehensive CLV metrics by industry in...\n",
            "   2. RESEARCH_AGENT ‚Üí None\n",
            "      Purpose: Analyze strategic expansion potential for top CLV ...\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
            "\n",
            "üî¨ RESEARCH_AGENT analyzing...\n",
            "   ‚ö†Ô∏è 15 unique error(s) during streaming\n",
            "   ‚úì Complete (16161 chars)\n",
            "   ‚Üí Routing to RESEARCH_AGENT\n",
            "üî¨ RESEARCH_AGENT analyzing...\n",
            "   ‚ö†Ô∏è 16 unique error(s) during streaming\n",
            "   ‚úì Complete (23545 chars)\n",
            "üìä Synthesizing results from 1 agent(s)...\n",
            "   ‚ö†Ô∏è 6 error(s) occurred during execution\n",
            "‚úÖ Analysis complete\n",
            "\n",
            "‚úÖ Run started!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüöÄ Starting evaluation run...\")\n",
        "print(f\"   Processing {len(queries_df)} queries through the multi-agent workflow\\n\")\n",
        "\n",
        "run.start(input_df=queries_df)\n",
        "\n",
        "print(\"‚úÖ Run started!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Waiting for invocations to complete...\n",
            "   Initial Status: RunStatus.CREATED\n",
            "\n",
            "‚úÖ Final Status: RunStatus.INVOCATION_COMPLETED\n",
            "   All invocations completed successfully!\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# ============================================\n",
        "# Wait for invocations to complete\n",
        "# ============================================\n",
        "print(\"‚è≥ Waiting for invocations to complete...\")\n",
        "print(f\"   Initial Status: {run.get_status()}\")\n",
        "\n",
        "wait_count = 0\n",
        "max_wait = 60  # Max 5 minutes (60 * 5 seconds)\n",
        "\n",
        "while run.get_status() != \"INVOCATION_COMPLETED\" and wait_count < max_wait:\n",
        "    time.sleep(5)\n",
        "    wait_count += 1\n",
        "    status = run.get_status()\n",
        "    if wait_count % 6 == 0:  # Print status every 30 seconds\n",
        "        print(f\"   [{wait_count * 5}s] Status: {status}\")\n",
        "\n",
        "final_status = run.get_status()\n",
        "print(f\"\\n‚úÖ Final Status: {final_status}\")\n",
        "\n",
        "if final_status == \"INVOCATION_COMPLETED\":\n",
        "    print(\"   All invocations completed successfully!\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è Run did not complete. Current status: {final_status}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error occurred while computing credits consumed for model claude-opus-4-5: Model claude-opus-4-5 not valid or not supported yet for cost estimation.\n",
            "Error occurred while computing credits consumed for model claude-opus-4-5: Model claude-opus-4-5 not valid or not supported yet for cost estimation.\n",
            "Error occurred while computing credits consumed for model claude-opus-4-5: Model claude-opus-4-5 not valid or not supported yet for cost estimation.\n",
            "Error occurred while computing credits consumed for model claude-opus-4-5: Model claude-opus-4-5 not valid or not supported yet for cost estimation.\n",
            "Error occurred while computing credits consumed for model claude-opus-4-5: Model claude-opus-4-5 not valid or not supported yet for cost estimation.\n",
            "Error occurred while computing credits consumed for model claude-opus-4-5: Model claude-opus-4-5 not valid or not supported yet for cost estimation.\n",
            "Error occurred while computing credits consumed for model claude-opus-4-5: Model claude-opus-4-5 not valid or not supported yet for cost estimation.\n",
            "Error occurred while computing credits consumed for model claude-opus-4-5: Model claude-opus-4-5 not valid or not supported yet for cost estimation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Metrics computation initiated!\n",
            "   Current Status: RunStatus.INVOCATION_COMPLETED\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Compute evaluation metrics\n",
        "# ============================================\n",
        "run.compute_metrics(metrics_to_compute)\n",
        "\n",
        "print(\"‚úÖ Metrics computation initiated!\")\n",
        "print(f\"   Current Status: {run.get_status()}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langgraph_snowflake",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
